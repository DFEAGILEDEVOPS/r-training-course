[
["index.html", "Introduction to R at DfE Preface and motivation", " Introduction to R at DfE Preface and motivation This resource is an introduction to the R programming language, which is a tool developed by statisticians across the world to do statistics, data analytics, create graphics, make dashboards and write reports. This online book can be used as standalone learning tool, or as part of training sessions. Chapters covered: Getting started with RStudio Downloading data for tutorial General Coding Loading and exploring data Data manipulation with dplyr Data visualisation with ggplot2 Statistical operations Iteration Functions Maps RMarkdown The art of the possible - show me what R is capable of The below links hopefully motivate some of the possible thing we can do with R, the first two are built in house at DfE. DfE Exclusion Statistics app built in RShiny DfE Exclusion Statistics statistical publication produced in RMarkdown Blogs on making beautiful charts Amazing map of Switzerland build in ggplot2 And finally Tom’s favourite, a gif of hurricane Irma hitting Florida built in ggplot2 Format of this training The format of the training is as follows: There will be a section of text describing what we will be doing Then there will be a code chunk showing what we will be typing, e.g. print(&quot;Hello world&quot;) There’ll also be activities for you to do to put your learning to the test, e.g. Activity A0.1: Write a line of code that prints the string “Hello world” Finally, we’ll also offer tips to make writing code easier Tip: R is better than Excel "],
["getting-started-with-rstudio.html", "Chapter 1 Getting started with RStudio 1.1 Opening R Studio 1.2 R Studio Layout 1.3 Setting up a project", " Chapter 1 Getting started with RStudio 1.1 Opening R Studio First thing, open up R Studio! Either find the RStudio icon on your desktop/start menu, or search for it in the start menu search (this is assuming you are using a Windows computer): 1.2 R Studio Layout Click on it and the R Studio interface will open, and will look like this: At this stage, there are three panes in an R Studio window: Left Panel: The console - this shows you which code you have run and any outputs you might specify, and also allows you to run lines of code which you don’t need to save (e.g. to remove an object) Top right: The environment - this is where R Studio shows you which objects (stuff - data tables, strings, numbers, personalised functions) you have available Bottom right: Everything else - the help function, the place to view graphs, and the place to view which files you have available 1.3 Setting up a project Analysis in R is carried out in ‘projects’. A ‘project’ creates an space which contains all of the inputs, code, and outputs that relate to the analysis. Activity A3.1: Create a new project: Click on File Click on New Project Click on New Directory Click on Empty Project In ‘Directory name’ type R_training In ‘Create project as subdirectory of’ select a folder that you commonly use, like Documents Click ‘Create project’ Click File Click New File Click R Script Great, we’ve now created a project - all pieces of analysis should start with a project. We now need to put some stuff in it. Activity A3.2: Set up your folder structure: Open up your file explorer and navigate to the directory (folder) you just created in R Studio Create the following folders: R Data Outputs Misc Your RStudio should look like this: Save this R script in the Scripts folder as R_training "],
["downloading-data-for-tutorial.html", "Chapter 2 Downloading data for tutorial", " Chapter 2 Downloading data for tutorial We’re going to use the publicly available underlying data from the Department for Education’s School Workforce Census, an annual census (collected every November and published in the following July) of every single teacher in England. You will need to: Click on this link to access the data Download the data using the button in the top right corner Save the file to the Data folder we created in section 1 . "],
["general-coding.html", "Chapter 3 General Coding 3.1 Objects 3.2 Comments 3.3 Good coding practice", " Chapter 3 General Coding Below shows RStudio with two places where you can run code A. An R Script allows you to save it for future use, meaning you can use it over and over again. B. The R Console will just print the code once, not allowing you to save this for future use. 3.1 Objects Objects are any ‘thing’ that you create in R. They’re shown in your Environment. There are a huge number of objects. The code below produces a few of these types of objects: my_string &lt;- &#39;DfE&#39; my_number &lt;- 2017 my_boolean &lt;- TRUE my_list &lt;- list(1,2,3,4,5) my_dataframe &lt;- data.frame(var1 = c(1,2,3,4,5), var2 = c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;,&quot;e&quot;)) The &lt;- sign is called a get sign. It ‘gets’ the output from the right hand side and attributes it to the object name. Tip: ALT + - is a shortcut to inputting the get sign. However, we still need to run that code. You’ll need to place your cursor somewhere in the line you want to run, or if it’s multiple lines highlight them. To initiate the code you can: Press CTRL + ENTER Click ‘Run’ in the top right hand corner of the script window In our environment in the top right hand corner, we will now have these 5 objects stored. Tip: There are a number of different ways you can write names in R: snake_case: lower case, separated by underscores CamelCase: each word starts with an upper case letter kebab-case: lower case, separated by hyphens Tip: Double click highlights term Triple click highlights line Quadruple click highlights entire script Activity A3.3: What does str(OBJECT NAME) do? Activity A3.4: Now save your work in the R folder! Writing the following code will remove a specified object: rm(object_name) Writing the following code will remove all objects: rm(list = ls()) Activity A3.5: Arguments are the bits of code inside brackets, and if there are multiple arguments they’re separated by commas. Explain the what the argument inside the second rm in the code above does. 3.2 Comments Activity A3.6: Type 1+1 and run it, what comes up in the console? Put a # in front of 1+1, what comes up in the console? Comments are really important for annotating code, so that you and others know exactly what the code does and why. Here we add a description of what setwd() does: #Remove all objects rm(list = ls()) Tip: CTRL + SHIFT + C comments multiple lines at once CTRL + SHIFT + R creates a section, which you can jump between using the dropdown list in the bottom left corner of the script window 3.3 Good coding practice We want to share our analysis with other R users, so it can be replicated. This needs to be as helpful as possible for other people to pick up your work. Everyone has their own style of coding, but with R and other langauges, we generally adopt a common practice to help team-working. The below style is a good starting point which will be helpful to your colleagues, but this is a very open topic which all R users have a preferred style! One example of helpful coding practice # comments out a section #### is a style preference which makes a natural break for your eyeline between sections of code ---- tells R that this is the start of a section of analysis, and users can click on the show document outline section and move between sections # Name of analyst, day/month/year # Name of task e.g. Analysis of KS4 data #### # Description of the work done # Identifies levels of pupil absence across years # Graphs results to see which years had highest levels of absence #### # Pseudocode ---- # 1. Load libraries and data # 2. Manipulate data # 3. Graph results #### # 1. Load data and libraries ---- library(tidyverse) raw_data &lt;- read.csv(&quot;my_data.csv&quot;) #### # 2. Manipulate data ---- raw_data %&gt;% filter(level == &quot;NATIONAL&quot;) -&gt; clean_data #### # 3. Graph results ---- ggplot(clean_data, aes(x = year, y = pupil_absence)) + geom_bar(stat = &quot;identity&quot;) "],
["loading-and-exploring-data.html", "Chapter 4 Loading and exploring data 4.1 Loading in data 4.2 Basic dataframe functions 4.3 Selecting certain columns/removing columns", " Chapter 4 Loading and exploring data 4.1 Loading in data The most common process to load in data is to load in a CSV file. #Load in data swfc_16_init &lt;- read.csv(&quot;data/SWFC_2016_Machine_Readable.csv&quot;) swfc_16 &lt;- swfc_16_init Tip: Load in and create and initial, raw version of the file, and never do anything to that object. This means if you muck anything up, you’ll always have a clean dataset to start again from. This is particularly important when loading in big dataframes, such as those from SQL. 4.2 Basic dataframe functions There are a number of functions which can be used to gain a summary of data: #Basic dataframe exploration functions summary(swfc_16) #Get a summary of each variable Tip: This worksheet is built using an add on to R called R Markdown, which integrates code, text, and images. We’ll come on to how to create R Markdown documents later, but for now, the box below with a white background and grey border is an output from the above code as it renders in R Markdown. Remember this, it will appear a lot in the worksheet. ## LA_Number Establishment_Number LAEstab_2016 ## Min. :201.0 Min. :1000 Min. :2013614 ## 1st Qu.:371.0 1st Qu.:2115 1st Qu.:3712144 ## Median :850.0 Median :3001 Median :8502761 ## Mean :697.6 Mean :3133 Mean :6979196 ## 3rd Qu.:891.0 3rd Qu.:3605 3rd Qu.:8912352 ## Max. :938.0 Max. :7750 Max. :9387022 ## ## LA_Name URN ## Lancashire : 632 Min. :100000 ## Kent : 581 1st Qu.:110587 ## Essex : 556 Median :120528 ## Hertfordshire: 535 Mean :122340 ## Hampshire : 531 3rd Qu.:137029 ## Birmingham : 447 Max. :143768 ## (Other) :18631 ## School_Name ## St Joseph&#39;s Catholic Primary School : 57 ## St Mary&#39;s Catholic Primary School : 41 ## St Anne&#39;s Catholic Primary School : 20 ## St Patrick&#39;s Catholic Primary School: 20 ## Holy Family Catholic Primary School : 19 ## St Peter&#39;s Catholic Primary School : 18 ## (Other) :21738 head(swfc_16) #Get the top 6 rows ## LA_Number Establishment_Number LAEstab_2016 LA_Name URN ## 1 331 4004 3314004 Coventry 141104 ## 2 332 2010 3322010 Dudley 103774 ## 3 330 4010 3304010 Birmingham 139788 ## 4 332 2012 3322012 Dudley 103775 ## 5 332 2043 3322043 Dudley 103781 ## 6 210 1025 2101025 Southwark 100768 ## School_Name ## 1 Seva School ## 2 Kates Hill Community Primary School ## 3 Waverley Studio College ## 4 Northfield Road Primary School ## 5 Dawley Brook Primary School ## 6 Ann Bernadt Nursery School tail(swfc_16) #Get the bottom 6 rows ## LA_Number Establishment_Number LAEstab_2016 LA_Name URN ## 21908 855 2092 8552092 Leicestershire 143250 ## 21909 831 2424 8312424 Derby 112728 ## 21910 882 2105 8822105 Southend-on-Sea 143341 ## 21911 936 2269 9362269 Surrey 142433 ## 21912 931 2561 9312561 Oxfordshire 137992 ## 21913 831 1009 8311009 Derby 112475 ## School_Name ## 21908 Newcroft Primary Academy ## 21909 Pear Tree Infant School ## 21910 Thorpe Greenways Infant School ## 21911 Lightwater Village School ## 21912 Faringdon Infant School ## 21913 Walbrook Nursery School colnames(swfc_16) #Get list of column names ## [1] &quot;LA_Number&quot; ## [2] &quot;Establishment_Number&quot; ## [3] &quot;LAEstab_2016&quot; ## [4] &quot;LA_Name&quot; ## [5] &quot;URN&quot; ## [6] &quot;School_Name&quot; ## [7] &quot;School_Type_Description&quot; ## [8] &quot;School_Type&quot; ## [9] &quot;School_Phase&quot; ## [10] &quot;Religious_Character&quot; ## [11] &quot;Government_Office_Region_Name&quot; ## [12] &quot;Parliamentary_Constituency&quot; ## [13] &quot;LA_District&quot; ## [14] &quot;Ward&quot; ## [15] &quot;StatutoryLowAge&quot; ## [16] &quot;StatutoryHighAge&quot; ## [17] &quot;Tot_Workforce_HC&quot; ## [18] &quot;Tot_Classroom_Teachers_HC&quot; ## [19] &quot;Tot_Teachers_Leadership_HC&quot; ## [20] &quot;Tot_Teachers_HC&quot; ## [21] &quot;Tot_TAs_HC&quot; ## [22] &quot;Tot_NonClassroom_Support_Staff_Exc_Aux_Staff_HC&quot; ## [23] &quot;Tot_Auxiliary_Staff_HC&quot; ## [24] &quot;Perc_PT_Teaching_Staff_&quot; ## [25] &quot;Tot_Workforce_FTE&quot; ## [26] &quot;Tot_Classroom_Teachers_FTE&quot; ## [27] &quot;Tot_Teachers_Leadership_FTE&quot; ## [28] &quot;Tot_Teachers_FTE&quot; ## [29] &quot;Tot_TAs_FTE&quot; ## [30] &quot;Tot_NonClassroom_Support_Staff_Exc_Aux_Staff_FTE&quot; ## [31] &quot;Tot_Aux_Staff_FTE&quot; ## [32] &quot;TA_Teacher_Ratio&quot; ## [33] &quot;Pupil_Teacher_Ratio&quot; ## [34] &quot;Perc_Male_Teachers&quot; ## [35] &quot;Perc_Minority_Ethnic_Teachers&quot; ## [36] &quot;Perc_Over_Age_50_Teachers&quot; ## [37] &quot;Perc_QTS_Teachers&quot; ## [38] &quot;Perc_of_Unqual_Teachers_who_Unqual_on_QTS_Route&quot; ## [39] &quot;Perc_Male_TAs&quot; ## [40] &quot;Perc_Minority_Ethnic_TAs&quot; ## [41] &quot;Perc_HLTA_TAs&quot; ## [42] &quot;Perc_Male_Non_Classroom_Support_Staff&quot; ## [43] &quot;Perc_Minority_Ethnic_Non_Classroom_Support_Staff&quot; ## [44] &quot;Perc_Male_Aux_Staff&quot; ## [45] &quot;Perc_Minority_Ethnic_Aux_Staff&quot; ## [46] &quot;Regional_Pay_Spine&quot; ## [47] &quot;Mean_Gross_Salary_All_Teachers_Sterling&quot; ## [48] &quot;Perc_Main_Pay_Range_Classroom_Teachers&quot; ## [49] &quot;Perc_Upper_Pay_Range_Leading_Practioners_Pay_Range_Classroom_Teachers&quot; ## [50] &quot;Perc_Receive_Allowance_Qual_Classroom_Teachers&quot; ## [51] &quot;Perc_Leadership_Pay_Range_Teachers&quot; ## [52] &quot;Perc_At_Least_One_Sickness_Absence_Teachers&quot; ## [53] &quot;Tot_Days_Sickness_Absence&quot; ## [54] &quot;Mean_Days_Lost_Teacher_Sickness_Absence_Of_Those_Taking_Sickness_Absence&quot; ## [55] &quot;Mean_Days_Lost_Teacher_Sickness_Absence_All_Teachers&quot; ## [56] &quot;FT_Vacant_Posts&quot; ## [57] &quot;Perc_FT_Posts_Vacant&quot; ## [58] &quot;FT_Temp_Filled_Posts&quot; ## [59] &quot;Perc_FT_Temp_Filled_Posts&quot; Tip: Click on the name of a dataframe to open it in a new window. Click on the arrow to the left of it to see the structure of it, or type str(DATAFRAME_NAME) s We can also change column names using the above function: #Identify the column number using colnames(swfc_16) and then specify the string to change it to colnames(swfc_16)[11] &lt;- &quot;Region&quot; #...and change it back again colnames(swfc_16)[11] &lt;- &quot;Government_Office_Region_Name&quot; 4.3 Selecting certain columns/removing columns Selecting certain columns is really helpful for creating subset dataframes. Below we select the school’s LA Establishment Code, its unique identifier, and all the columns to do to do with teacher absences: teacher_absences &lt;- swfc_16[,c(2,53:55)] Let’s break this down: teacher_absences is the name of the new dataframe we’re going to create We’ve seen the get sign before swfc_16 is the dataframe we’re going to select columns from [] is for selecting a certain element from an object c() stipulates a character string, in this instance a load of numbers x:y means all numbers between and including x and y The comma and nothing before it signifies that all rows must be included - the format is dataframe[row conditions, column conditions] Whilst we can use this method to remove columns, we can also remove individual columns using a simpler method. Say for instance we wanted to remove the 2016 LA Establishment Code, the third column: swfc_16 &lt;- swfc_16[,-3] "],
["manipulating-dataframes.html", "Chapter 5 Manipulating Dataframes 5.1 Conditional Selections 5.2 Altering data in dataframes 5.3 Writing data", " Chapter 5 Manipulating Dataframes 5.1 Conditional Selections We can select subsets of dataframes based on certain conditions. There are a number of ways to do it, but this method uses functions in the basic R set of functions, known as ‘base R’: #Conditionally select primary schools swfc_16_pri &lt;- swfc_16[swfc_16$School_Phase == &quot;Primary&quot;,] Let’s break this down: swfc_16_pri is the name of the new dataframe we’re going to create We’ve seen the get sign before swfc_16 is the dataframe we’re going to conditionally select rows from [] is for selecting a certain element from an object $ is for extracting an element by name, in this instance the School_Phase column ==“Primary” signifies that rows must equal Primary The comma and then nothing after it signifies that all columns must be included - the format is dataframe[row conditions, column conditions] Activity A5.1: Use conditional selections to create a new dataframe which contains all schools whose school type is an academy. Open the dataframe to see what an academy is actually called in School_Type. Tip: After typing the dollar sign when looking for dataframe column names, pause, and a dropdown list will appear. We can also use selections on numerical variables too: swfc_16_male &lt;- swfc_16[swfc_16$Perc_Male_Teachers &gt; 50,] However, we’re not limited to just one condition: #Conditionally select schools where Pupil:Teacher Ratios are below 20 and above or equal to 10 swfc_16_ptr &lt;- swfc_16[(swfc_16$Pupil_Teacher_Ratio &lt; 20 &amp; swfc_16$Pupil_Teacher_Ratio &gt;=10),] #Conditionally select schools where Pupil:Teacher Ratios are below 10 or their LA is in Camden swfc_16_ptr_camden &lt;- swfc_16[(swfc_16$Pupil_Teacher_Ratio &lt; 10 | swfc_16$LA_Name == &quot;Camden&quot;),] Activity A5.2: Select all schools whose StatutoryLowAge is higher than 5 and have no full time posts vacant (the fourth from last column). 5.2 Altering data in dataframes Editing dataframes is a key skill. We can edit the data within columns, or create new ones. Here we edit the Religious_Character to be TRUE or FALSE. The Religious_Character column is a column of factors - strings limited to a certain number of entries. We will first turn it into a column which can contain any string, called a character column. Tip: If a column is a factor, you can see what the different entries are through levels(dataframe$column). #Turn Religious.Character to binary swfc_16$Religious_Character &lt;- as.character(swfc_16$Religious_Character) swfc_16$Religious_Character[swfc_16$Religious_Character == &#39;Does not apply&#39; | swfc_16$Religious_Character == &#39;None&#39; | swfc_16$Religious_Character == &quot;&quot;] &lt;- FALSE swfc_16$Religious_Character[swfc_16$Religious_Character != FALSE] &lt;- TRUE This uses boolean logic (TRUE or FALSE). It also uses != which means does not equal. We can calculate a new column too. In this instance we’ll work out the percentage of teaching staff that are vacancies. #Calculate percentage of posts which are vacancies swfc_16$perc_vacancies &lt;- swfc_16$FT_Vacant_Posts/swfc_16$Tot_Teachers_HC Activity A5.3: Turn all schools which arent an LA maintained school or a special school into ‘Not LA maintained’. 5.3 Writing data Activity A5.4: The function for writing is write.csv(). Use the help function (?write.csv) to work out what the arguments are for this function "],
["data-manipulation-with-dplyr.html", "Chapter 6 Data manipulation with dplyr 6.1 Packages 6.2 The pipe 6.3 Joining 6.4 Selecting 6.5 Pivoting 6.6 Filtering 6.7 Mutating", " Chapter 6 Data manipulation with dplyr 6.1 Packages One of the great things about R (and lots of other open source programming languages) is that you can add in extra functionality really easy. These extra functions come in the form of packages. To get a package, we first need to install it. This can be done in the console, as once installed, we don’t need to reinstall every time we start a new session of R. We are going to install a package called dplyr, a package to manipulate data. install.packages(&quot;dplyr&quot;) A lot of funny stuff will come up in your Console, ignore it, it’s all normal (or should be!). Once we’ve installed it, we have to load the package. This we do have to do every time we start a new session of R. #Load required libraries library(dplyr) 6.2 The pipe The first feature we’ll look at is the pipe: %&gt;%. The pipe actually comes from a package which dplyr is dependent on in order to run (these types of packages are called dependencies) called magrittr and so is installed when dplyr is installed. The pipe allows you turn code into the format of a recipe, carrying out a series of functions one after another. For example, we could turn the name of the school (School_Name) into a character from a factor, as it is not a categorical variable where the records could take one of a fixed number of entries. In base R, this would look like: swfc_16$School_Name &lt;- as.character(swfc_16$School_Name) In dplyr this looks like: swfc_16$School_Name &lt;- swfc_16$School_Name %&gt;% as.character() The pipe gives a more logical approach - putting the ingredients (swfc_16$Perc_Teachers_QTS) into recipe steps. We don’t have to include arguments which specify which object we’re operating on, as this is specified when we input the ingredients. Tip: You can shortcut to a pipe by CTRL + SHIFT + M. 6.3 Joining There are a number of types of joins that dplyr offers. We won’t go through them here as this isn’t what this course is about, but this post goes through them clearly. We will use a left join - keeping all rows on one dataframe, joining another on a certain variable where they match, and making all rows which don’t match ‘not applicable’. We will create a dataframe which details whether a Government Office Region is in London or the Rest of England and then match it to the rest of the School Workforce Census. #Create dataframe on whether region is in London or Rest of England ldn_roe &lt;- data.frame(Government_Office_Region_Name = c(&quot;East Midlands&quot;, &quot;East of England&quot;, &quot;Inner London&quot;, &quot;North East&quot;, &quot;North West&quot;, &quot;Outer London&quot;, &quot;South East&quot;, &quot;South West&quot;, &quot;West Midlands&quot;, &quot;Yorkshire and the Humber&quot;), ldn_roe = c(&quot;RoE&quot;,&quot;RoE&quot;,&quot;LDN&quot;,&quot;RoE&quot;,&quot;RoE&quot;,&quot;LDN&quot;,&quot;RoE&quot;,&quot;RoE&quot;,&quot;RoE&quot;,&quot;RoE&quot;)) #Match to SWFC swfc_16 &lt;- left_join(swfc_16,LDN_RoE,by=&quot;Government_Office_Region_Name&quot;) We can also match on column names even if they columns are named differently. But first, we’ll remove the column that we’ve just added in using the ‘select’ function. 6.4 Selecting The select function uses column names to select subsets of a dataframe. Individual columns can be selected, separated by columns, or groups of columns, with the starting and ending columns separated by a colon. #Remove new column swfc_16 &lt;- select(swfc_16,LA_Number:Perc_FT_Temp_Filled_Posts) #Or using &#39;the pipe&#39; swfc_16 &lt;- swfc_16 %&gt;% select(LA_Number:Perc_FT_Temp_Filled_Posts) Now, we can change the name of the first ldn_roe column, and then match again. #Change name of Government_Office_Region_Name ldn_roe &lt;- ldn_roe %&gt;% select(Region = Government_Office_Region_Name, ldn_roe) #Match to SWFC swfc_16 &lt;- left_join(swfc_16,ldn_roe,by=c(&quot;Government_Office_Region_Name&quot;=&quot;Region&quot;)) 6.5 Pivoting Pivoting (grouping data by certain characteristics and then performing certain calculations - counts of each group or averages for each group) is a really popular feature in Excel, and can be replicated using dplyr. We’re going to create two pivot tables: Count the number of each type of school Calculate the average % of teachers with Qualified Teacher Status for each school type The image below shows the boxes from the Excel pivot table user interface with the entries to build the pivot table for the first of the list above. #Calculate the number of schools by school type school_type_count &lt;- swfc_16 %&gt;% #Set the name of the output object and feed in &#39;the ingredients&#39; - swfc_16 in this instance group_by(School_Type) %&gt;% #Recipe step 1: Specifying the variable we want to group the data by summarise(Count_Schools = n()) #Recipe step 2: Define what function we want to apply to the grouped data. Here we are doing a simple count - n(). We also specify the name of the new column, in this instance &#39;Count_Schools&#39; Tip: To prevent your lines of code being too long you can start new lines after things like %&gt;%, ,, =, and &lt;-. If you go to ‘Tools’, ‘Global Options’, ‘Code’, ‘Display’ there is an option called ‘Show margin’ which adds a margin after 80 characters as a default - try not to exceed this. #Calculate average percentage of qualified teachers per school, grouped by school type av_qts_schooltype &lt;- swfc_16 %&gt;% #Set the name of the output object and feed in &#39;the ingredients&#39; - swfc_16 in this instance group_by(School_Type) %&gt;% #Recipe step 1: Specifying the variable we want to group the data by summarise(Ave_Perc_QTS = mean(Perc_QTS_Teachers,na.rm=TRUE)) #Recipe step 2: Calculate the average percentage of qualified teachers for each group. The &#39;na.rm=TRUE&#39; argument does not consider rows where the value is NA. Activity A6.1: Calculate the total number of full time posts which are vacant, by Government Office Region, using the function sum(column,na.rm=TRUE). Remember to turn the full time posts column into a data type which can be summed. 6.6 Filtering When we looked at conditional selections earlier, we were essentially looking at a way of filtering data. There’s a neater way of doing this with dplyr: #Select all schools in Inner and Outer London swfc_16_lon &lt;- swfc_16 %&gt;% filter(grepl(&quot;London&quot;,Government_Office_Region_Name)) #The filtering function is unsurprisingly called &#39;filter()&#39; #Here, we&#39;re using a function called grepl, which finds all rows where the Government_Office_Region_Name column contains the string &#39;London&#39;. Activity A6.2: Use !is.na() to filter out all schools without a value for the percentage of teachers who are qualified. Explain what !is.na() does. 6.7 Mutating The mutate() function allows you to alter data in the dataframe, as we did a few sections ago. Let’s take the code above where we calculated the number of schools of each type of school, bolt on some more recipe steps, and calculate the percentage of schools in each group. #Calculate the percentage of schools by school type school_type_count &lt;- swfc_16 %&gt;% group_by(School_Type) %&gt;% summarise(Count_Schools = n()) %&gt;% mutate(Perc_Schools = Count_Schools/sum(Count_Schools)) Let’s break this down: We’ve used the mutate function We’ve created a new column called Perc_Schools Perc_Schools equals the count for each school type, divided by the total number of schools, calculated using sum() We can also mutate a column without creating a new column: #Calculate the percentage of schools by school type school_type_count &lt;- swfc_16 %&gt;% group_by(School_Type) %&gt;% summarise(Count_Schools = n()) %&gt;% mutate(Perc_Schools = Count_Schools/sum(Count_Schools)) %&gt;% mutate(Perc_Schools = round(Perc_Schools*100,1)) #Multiply Perc_Schools by 100 to get a percentage, and round to 1 decimal place. Activity A6.3: The big one - use dplyr to find out what percentage of secondary school (not including all through school) teaching assistants the East of England has. These are the functions you’ll need to run: A filter Pivoting using a sum Mutating Filtering on ‘East of England’ Selecting the value column Using as.numeric() to return just one number Hint: Write each step of code, run it, check it works, and then add the next recipe step in. "],
["data-visualisation-with-ggplot2.html", "Chapter 7 Data visualisation with ggplot2 7.1 ggplot2 7.2 Scatter plots 7.3 Bar charts 7.4 Line graphs 7.5 Displaying a third variable 7.6 Styles", " Chapter 7 Data visualisation with ggplot2 7.1 ggplot2 Another package in the tidyverse is ggplot2, used for plotting anything from graphs to maps. R has a function built into it to plot graph, unsurprisingly called plot(). However, it’s limited compared to ggplot2, which is part of the tidyverse package. Activity A7.1: Install either the ggplot2 package or the tidyverse package of packages, of which ggplot2 is one. Remember to load it up using library()! The main function in ggplot2 is ggplot, which stands for the ‘grammar of graphics’. The ‘grammar of graphics’ relates to the three elements that makes up a graphical visualisation: A dataset from which the visualisation is built Visual marks that represent the data A coordinate system - a grid on which the data is plotted In this section we’ll look at how to plot three different types of graph: Scatter plots Bar charts Line graphs We’ll also look at how to show how data of different groups can be displayed and how to alter the style of graphs. First, let’s look at the basic functions: ggplot(dataset,aes(x,y)) + geom_*() + coords_*() + styles() + styles() Let’s break this down: The first argument of the main function, ggplot, is the dataset from which the data will come from (the first of our graphical elements) The second argument, the aesthetics, in the ggplot function are the specific columns within the dataset which make up the x and y axis (also part of the first of the graphical elements) The geom_* functions, where the asterisk details the type of visualisation, is used to detail how the visual marks are displayed (the second of the elements) The coords_* functions are optional in defining the coordinate system, but if no functions are included, a standard x-y grid will be produced (the third, and least commonly used of the elements) Further multiple and optional styles can be added on Each of these are joined together with plus signs. 7.2 Scatter plots A scatter plot is a plot of points where each point is defined by a dataset’s entry’s for two variables, creating x and y axes. Here we’ll create a scatter plot (or geom_point() as it is known in ggplot) to compare the total workforce in a school and the total teaching workforce. ggplot(swfc_16,aes(Tot_Workforce_HC,Tot_Teachers_HC)) + geom_point() Activity A7.2: Explain the arguments in this graph. 7.3 Bar charts We can use bar charts to do simple counts of the number of observations belonging to each level. In the example below we use the geom_bar() function to count the number of schools of each school type: ggplot(swfc_16,aes(School_Type)) + geom_bar() Activity A7.3: What’s different about the aes() function and why? However, as well as counts we can use bar charts to display the values within the column of a dataframe. Here we calculate the average percentage of teachers with qualified teacher status for each school type. ggplot(swfc_16 %&gt;% group_by(School_Type) %&gt;% summarise(ave_perc_qts = mean(Perc_QTS_Teachers,na.rm=TRUE)), aes(School_Type,ave_perc_qts)) + geom_bar(stat=&quot;identity&quot;) Let’s break down the arguments: The first argument within ggplot() is a dplyr script to create a dataframe which contains each school type and its average percentage of qualified teachers. This negates the need to, every time, create a named dataframe. Activity A7.4: Highlight the first argument and run it. The aes() function contains two arguments this time - the x-axis and the y-axis. We need to define a y-axis because we’re going to be using values from a column, not just counts. The geom_bar() function contains an argument, stat=‘identity’, which informs the plot that it’s to use the values from a column (in this instance the ave column created in the first argument of ggplot()). 7.4 Line graphs Activity A7.5: Adjust the code above for the bar graph to produce a line graph: Replace geom_bar(stat=“identity”) with geom_line() Change the columns used to see how the TA:Teacher ratio (TA_Teacher_Ratio) varies with the total number of teachers in a school (Tot_Teachers_HC). A word of warning with line graphs though: you can use bar charts and line graphs to display changes between discrete numerical data (e.g. 1,2,3,4,5), but you should not use a line graph to display changes between categorical data (e.g. primary schools, secondary schools, special schools). This is because a line graph implies some sort of continuous variation, so each mark has a ‘distance’ from the previous (e.g. the distance between 2 and 1 is 1), but there’s no ‘distance’ between primary school and secondary school. ggplot(swfc_16 %&gt;% group_by(Tot_Teachers_HC,School_Type) %&gt;% summarise(ave_ta_teacher_ratio = mean(TA_Teacher_Ratio,na.rm=TRUE)), aes(Tot_Teachers_HC,ave_ta_teacher_ratio)) + geom_line() 7.5 Displaying a third variable We can use ggplot to plot three variables, not just two on the x and y axes. This allows the viewer to get a more detailed breakdown of the data, without having to produce multiple graphs. There are three different arguments which can be added to the aesthetic function (as they’re going to change how the graph looks), depending on what type of graph is being produced: fill= is used for bar graphs - this splits up each bar with different colours related to the proportion of each category making up that bar col= is used for line graphs - this creates lines of different colours for each different category to show how it varies size= is used for scatter plot - the size of each point relates to the value in the column In all of these arguments, after the equals sign comes the variable name that we want to plot. Here’s an bar chart example which uses fill which shows the proportions of each type of school which make up each region. Activity A7.6: Use col to adapt the line graph above to show how different each different school type’s TA:Teacher ratio varies with size of school. Finally, we’re going to use size to show a third variable on a scatterplot. Activity A7.7: Use the group_by and summarise functions in dplyr to create a dataframe which has four columns: Government Office Regions The average pay (Mean_Gross_Salary_All_Teachers_Sterling) for each of those regions The average percentage of teachers receiving allowances (Perc_Receive_Allowance_Qual_Classroom_Teachers) in each region The number of schools in each region (use n()) Your code in the summarise function will look something like: summarise(var1_name = mean(variable1,na.rm=FALSE), var2_name = mean(variable2,na.rm=FALSE), var3_name = n()) Activity A7.8: Pop your dataframe code from the activity above into a ggplot function, and create a scatter plot with the col argument as the region and the size argument as the number of schools in that region. It may seem like it should be fill not col for colouring points, but remember that a point shouldn’t really have a size - it’s an exact location, so there’s nothing to fill! 7.6 Styles So, we’ve produced a number of graphs now, but they’re not the best formatted in places… Fortunately, one of ggplot’s major selling points is that it’s really versatile with the formatting that can be done. Here are a few handy functions, all of which are added with a plus sign after you’ve detailed what plot you want: coord_flip() flips the coordinates, so the x axis is on the y axis and vice versa. This is really useful for bar graphs, to prevent labels overlapping ggtitle() allows you to specify a chart title - the argument within this function is enclosed in quotes and details what title is required xlab/ylab specify the x and y axis labels respectively and again the argument, which is the label, is enclosed in quotes theme_minimal() removes the grey background, which immediately makes it look nicer! xlim/ylim specifies the limits for continuous axes on the x and y axes respectively. They take two arguments - the lower limit and the upper limit, separated by a comma. Activity A7.9: Apply all of these functions to the graphs you’ve previously produced. "],
["statistical-operations.html", "Chapter 8 Statistical operations 8.1 Maximum, Minimum, and Range 8.2 Averages 8.3 Correlations 8.4 Significance Testing", " Chapter 8 Statistical operations Easily drilling down into data is one of R’s most powerful functions. As we would with Excel, we can use a number of functions to gain a better understanding of the data. 8.1 Maximum, Minimum, and Range One of the key checks to do on a dataset when loading data in is what extreme values are in each variable: The minimum The maximum The range Tip: Put closing delimiters* on a new line - it’s easier to see which opening delimiter it corresponds to. *(), {}, [] Now, we can calculate the minimum and maximum for any column we require: min(swfc_16$Pupil_Teacher_Ratio) max(swfc_16$Pupil_Teacher_Ratio) Activity A8.1: It’s coming up with NA. What’s the argument in min or max that we need to add in to return a result? We could also write this using the pipe: swfc_16 %&gt;% select(Pupil_Teacher_Ratio ) %&gt;% min(ARGUMENT_IN_HERE ) swfc_16 %&gt;% select(Pupil_Teacher_Ratio ) %&gt;% max(ARGUMENT_IN_HERE ) These two functions are really useful for identifying extreme values and outliers - potentially values which are incorrect or shouldn’t be there. We can use another function, similar to min and max, called range. Activity A8.2: Pick a variable and calculate the range. Think about the arguments you need to use. Tip: Statistical functions nearly always need to have NA values removed from the object they’re operating on. 8.2 Averages There are two averages we can calculate: Mean: This is the ‘average’ that we’re used to - add the values up and divide them by the number of values Median: Line them all up in order, count to the middle value (if its an even number of values, go for halfway between the two middle values) Let’s apply each of these to a subset of the main dataset. Mean: #The mean of the total school workforce for primary schools swfc_16 %&gt;% filter(School_Phase == &#39;Primary&#39;) %&gt;% group_by(School_Phase) %&gt;% summarise(Ave = mean(Tot_Workforce_HC,na.rm=TRUE)) Median: #The median of the total school workforce for primary schools swfc_16 %&gt;% filter(School_Type == &#39;Academies&#39;) %&gt;% group_by(School_Type) %&gt;% summarise(Ave = median(Tot_Workforce_HC,na.rm=TRUE)) 8.3 Correlations We can calculate correlations between 2 or more values. Let’s just start with two variables: #Base R cor(swfc_16[,c(15,16)],use=&quot;complete.obs&quot;) ## StatutoryHighAge Tot_Workforce_HC ## StatutoryHighAge 1.0000000 0.6099884 ## Tot_Workforce_HC 0.6099884 1.0000000 #Pipes swfc_16 %&gt;% select(StatutoryLowAge,StatutoryHighAge)%&gt;% cor(use=&quot;complete.obs&quot;) ## StatutoryLowAge StatutoryHighAge ## StatutoryLowAge 1.0000000 0.7454194 ## StatutoryHighAge 0.7454194 1.0000000 #use=&quot;complete.obs&quot; means only use the observations where the data is present in both columns Activity A8.3: Create an object (a correlation matrix) which has the correlations for all the columns between StatutoryLowAge and Tot_TAs_HC. Assign it to an object name. 8.4 Significance Testing This isn’t a stats course, but significance testing is a really handy technique for analysing data - the first step in learning statistical techniques in a data analyst’s/scientist’s toolkit, and can be relatively easily executed in R. In practical terms, significance testing is quantifying how confident we are two groups are different to one another. Suppose we wanted to test whether primary schools had significantly different total workforces to the school population overall. t.test(swfc_16 %&gt;% filter(School_Phase == &quot;Primary&quot; ) %&gt;% select(Tot_Workforce_HC), mu = mean(swfc_16$Tot_Workforce_HC,na.rm=TRUE), alternative = &quot;less&quot;) t.test(swfc_16[swfc_16$School_Phase == &quot;Primary&quot;,17], mu = mean(swfc_16$Tot_Workforce_HC,na.rm=TRUE), alternative = &quot;less&quot;) Let’s break the input down: t.test(): The technique to test for a significant difference is called a T-test - in this instance we’re carrying out a ‘one-tail’ T-test, which in this instance means checking whether the average of a sample significantly differs from the average of the entire population. Argument 1: The first argument is the sample that we want to the population against. In this instance it’s primary schools. Argument 2: mu is the average of the population. Argument 3: We want to test whether the sample average is ‘less’ than population average. This could also be ‘greater’. ## ## One Sample t-test ## ## data: swfc_16 %&gt;% filter(School_Phase == &quot;Primary&quot;) %&gt;% select(Tot_Workforce_HC) ## t = -67.484, df = 16683, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean is less than 59.69092 ## 95 percent confidence interval: ## -Inf 46.84931 ## sample estimates: ## mean of x ## 46.52847 Now let’s break the output down (in reverse order from how it’s displayed): Mean of x: This is the average of the sample: 46.5287. Confidence intervals: 95% of the time (i.e. 19 out of 20 times), the average of any random sample of the overall population will be outside the confidence intervals. Here, because we’re only checking whether the sample’s average than the population’s average, we only need a confidence interval above the mean: 46.84931. p-value: To be confident that there is a significant difference, this number needs to be less than 0.05 (i.e. only 1 time out of 20 will a random sample of primary schools we take from the population be smaller than the upper confidence interval. Simple?!? Activity A8.4: Test whether schools in Camden LA District have a significantly higher percentage of vacant posts (column name is FT_Vacant_Posts) than England as a whole, using a t-test. Repeat for lower. As well as comparing a sample to a population we can compare two samples. What we are doing is testing whether the difference of the averages of two samples is significantly different to zero, i.e. there is a difference. In this example we’re going to test whether primary schools have a significantly different percentage of teachers who are male to schools that have a phase of ‘All Through’. t.test(Perc_Male_Teachers ~ School_Phase, data = (swfc_16 %&gt;% filter(School_Phase == &quot;Primary&quot; | School_Phase == &quot;All Through&quot;) %&gt;% select(School_Phase, Perc_Male_Teachers))) Let’s break the input down: t-test: As above Argument 1: This contains the variable that we’re going to compare the groups on (percentage of teachers that are male), and the characteristic that defines the groups (phase). But there’s more than one phase of school I hear you say… Argument 2: Fear not. In the second argument we use some dplyr to do some filtering. We only select schools that are primary or all through, and we only select the school phase and percentage of teachers that are male columns. ## ## Welch Two Sample t-test ## ## data: Perc_Male_Teachers by School_Phase ## t = 22.812, df = 151.8, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 15.56238 18.51366 ## sample estimates: ## mean in group All Through mean in group Primary ## 31.81972 14.78170 Now let’s break the output down: Welch: Dunno who Welch is, but their t-test is the standard one for testing two samples Group means (at the bottom): These are the means of the two samples that we’re comparing Confidence intervals: 95% of the time (i.e. 19 out of 20 times), the average of any random samples taken from each of the groups (primary and all through) will have a difference in their averages of between 15.56238 and 18.51366. Both of those numbers are above 0, so this is looking good… p-value: Again, to be confident that there is a significant difference, this number needs to be less than 0.05 (i.e. only 1 time out of 20 will random samples from primary schools and all through schools be outside the confidence intervals above) Activity A8.5: Test whether schools in Camden and Northumberland LA Districts have significantly different percentage of vacant posts (column name is FT_Vacant_Posts) than England as a whole, using a two sample t-test. Tip: For more info on t-tests, go to this page on dummies.com. Also, try out this page for an interactive two sample t-test calculator if you want a bit more practice. "],
["iteration.html", "Chapter 9 Iteration 9.1 if 9.2 for loops 9.3 while loops 9.4 How could we use loops?", " Chapter 9 Iteration One of the most powerful uses of any programming language is its ability to do a task over and over again really quickly - this is known as iteration. Tip: Iteration isn’t actually the most efficient way of writing code, because it processes each item it iterates over one at a time. A more efficient way to process code is to ‘vectorise’ your code - this means writing code to process all the items at once. We’ve already done this when we’ve been manipulating columns of data in one go - we could have written an iterative function to go over each item in the column and manipulate it. That said, iteration is a really important process to learn, because it helps you understand the sort of ‘decisions’ a computer will make in the background when executing code. There are three types of iterative function that we’ll look at: An if statement - a function that will do one thing if a condition is met or is true, and another thing is that condition is not met or is false A for loop - a function that will repeat a task for every item in a list or a certain number of iterations A while - function that will repeat a task for as long as a condition is met or is true All of the functions here take a similar format: function(condition to be met){ action to be carried out if condition is met #Note how it has to be indented } 9.1 if As mentioned above, if statements are for carrying out an action if a condition is met or is true. For example, say we were trying to create a recreate whether a fictitious teacher was male or female, if we knew the probability that a teacher was male, we could build an if statement that said: Generate a random number between 0 and 1 If that number is less than or equal to the probability that a teacher is male, then say our fictitious teacher is male If that number is more than the probability that a teacher is male, then say our fictitious teacher is female First, let’s work out the probability that a teacher is male. This is the average percentage of male teachers divided by 100, to make it a probability. prob_male &lt;- swfc_16$Perc_Male_Teachers %&gt;% mean(na.rm = TRUE)/100 Now, let’s generate our random number using the runif function. rand_num &lt;- runif(1) Now let’s write our if statement. if(rand_num&lt;=prob_male){ print(&quot;M&quot;) } So now if our random number is less than or equal to the probability a teacher is male that it will print ‘M’. However, if it’s over the probability, nothing will happen. To ensure something does happen we can use the else function, which will execute an action if the condition is not met. if(rand_num&lt;=prob_male){ print(&quot;M&quot;) }else{ print(&quot;F&quot;) } Activity A9.1: How could we streamline the code we’ve just written by replacing object names? 9.2 for loops A for loop - a function that will repeat a task for every item in a list or a certain number of iterations. Say we wanted to create a fictitious school which contained 10 teachers, we could write a for loop that for 10 iterations repeated the if statement above. for(i in 1:10){ if(runif(1)&lt;=prob_male){ print(&quot;M&quot;) }else{ print(&quot;F&quot;) } } Let’s break this down the for loop argument: The i is the name of an object that will take a different value at each iteration (1st iteration, 2nd iteration, etc) of the for loop in 1:10 details the different values i will take: 1st iteration - i=1, 2nd iteration i=2, etc. The action to execute at each stage between the curly braces, which in this instance is the if statement from above Activity A9.2: Adapt the for loop above to create an empty object and at each iteration add the result from the if statement to that object. The functions you’ll need are below: #For creating an empty object character(0) #For joining values to an existing object c(object,value) 9.3 while loops A while loop while perform an action for as long as the condition specified in the function’s argument is true. Activity A9.3: Write the function below out and run it. As 2 while always be greater than 1 what is going to happen? while(1&lt;2){ print(&quot;This is going to take a while...&quot;) } Tip: Stop a bit of code from running by clicking on the red stop sign in the top right hand corner of the console. Typically, a while loop will look like this: object &lt;- starting_value while(condition_of_object){ action object &lt;- change_value_of_object } #For example i &lt;- 1 while(i&lt;5){ print(paste0(&quot;This is a while loop, we&#39;re at iteration &quot;, as.character(i))) i&lt;-i+1 } Tip: paste0() is a really useful function that glues strings together. It’s different to c() in that it turns multiple strings into one string, whereas c() turns them into a vector of multiple strings. Activity A9.4: Add 3 while loops after your for loop above so that while i equals 1 you add ‘Headteacher’ to an object, while i is less than 5 you add ‘Senior Leader’ to the same object, and while i is greater or equal to 5 you add ‘Classroom Teacher’ to the same object. Once this has run put the gender object and the object denoting the seniority of the teacher into a dataframe called my_school with the column headings as gender and grade. 9.4 How could we use loops? Loops are really useful for building models of systems, to use probabilities (as we did with the gender probabilities) to predict how entities (called agents in modelling) will behave in a system. These models can be run multiple times and the outputs recorded each time to give a distribution of how likely each outcome is to occur based on different behaviours along the modelled actions. "],
["functions.html", "Chapter 10 Functions 10.1 Writing functions 10.2 Applying functions repetitively", " Chapter 10 Functions We’ve used a lot of functions up until now, and understand the format of a function, with the function name and then the arguments inside the brackets. It essentially takes the form: verb(noun,adverbs) Where the verb is the thing we want to do, the noun (as the first argument) is the object we want to do it to, and the adverbs (as the subsequent arguments) are the descriptions of how we want to do it. However, there’s going to come a time when we want to do the same thing again and again, to a lot of different objectives, and there won’t be a specific function to write it. Don’t worry though, you can do write your own functions. 10.1 Writing functions A function is comprised of three parts: function_name &lt;- function(function_argument1,function_argument2,etc){ function_actions } So, a function that divides an object by 100 looks like this: my_func &lt;- function(x){ x/100 } Here x is the noun that we’re doing something to. To create the function, simply run that code. Activity A10.1: Use mutate and multiply Perc_PT_Teaching_Staff_ by 100 in a new column called perc_pt_test. Activity A10.2: Remember the code from the iteration section on deciding whether a fictional teacher was male or female? if(rand_num&lt;=prob_male){ print(&quot;M&quot;) }else{ print(&quot;F&quot;) } Turn that into a function, with the random number as the ‘noun’. Once you’ve written it, run it with a few different numbers in the argument. It’s also really handy for producing graphs when we want to filter them by different categories. Say we wanted to look at a histogram of the total school workforce, to get an idea of the distribution of school sizes in a particular region, we could make a graph like this (with Inner London as an example): ggplot(swfc_16 %&gt;% filter(Government_Office_Region_Name == &#39;Inner London&#39;), aes(Tot_Workforce_HC)) + geom_histogram() + ggtitle(&#39;Distribution of school size in Inner London&#39;) However, ‘Inner London’ could be any one of the 9 other regions in England - we could vary this value. By varying it we are making it a parameter - a value in our input code that can change. We can produce exactly the same output by replacing the string ‘Inner London’ with an object name, and creating that object before we create the graph (remember the paste0 function that we used in the iteration section). region_name &lt;- &#39;Inner London&#39; ggplot(swfc_16 %&gt;% filter(Government_Office_Region_Name == region_name), aes(Tot_Workforce_HC)) + geom_histogram() + ggtitle(paste0(&#39;Distribution of school size in &#39;,region_name)) Activity A10.3: Using the code above, create a function which you could put in any region name, and as long as that region is correct, the function produces a graph. 10.2 Applying functions repetitively Writing a lot of code get boring and laborious. Writing a lot of code that does the same thing again and again gets really boring and laborious. It can also lead to errors - if you copy and paste code enough times eventually you’ll make a mistake, which could lead to incorrect analysis. However, as already mentioned, if you’re doing something again and again, then building a function is really useful. Suppose we do want to create graphs of all 10 regions, using the code above? We have the function to produce a graph, what we need now is to work out how to repeat the graph again and again, changing the region parameter. We could use a for loop, but remember that’s not the most effective way. We want to ‘vectorise our code’. A function called lapply applies a function to a list of objects. Activity A10.3: The Government_Office_Region_Name column is a factor column - use levels() to generate a list of the different possible entries to that column The lapply function works in the following way: lapply(multiple_objects_to_apply_function_to,function(argument_name) specific_function_to_apply(argument_name)) The word function at the start of the second argument specifies that you’re about to write a function name, and essentially says ‘make each object in the list in the first argument the value of argument_name and apply the specific function to it’. You can choose any string you like for argument_name, as long as it’s the same in both places. Activity A10.3: Use lapply to print a graph showing the distribution of school sizes in the Plot pane for every single region in England. We can also use lapply to do the same thing to data in multiple columns. The difference here is that we want to turn the outputs of the lapply into an object. That object just so happens to be the same thing that goes in to the first argument in lapply. So if we wanted to turn all the columns with ‘Perc’ in the column title, that is those columns that are a percentage, from a number out of 100 to a number out of 1, by dividing by 100, we’d apply the following code: swfc_16[,grep(&quot;Perc&quot;, colnames(swfc_16))] &lt;- lapply(swfc_16[,grep(&quot;Perc&quot;, colnames(swfc_16))],function(x) my_func(x)) Let’s break this down: swfc_16[,grep(“Perc”, colnames(swfc_16))] are all the columns in swfc_16 which contain ‘Perc’. The function grep finds all the columns which contain the substring ‘Perc’. Within lapply, the first argument is the same set of columns - we’re essentially doing an update on those columns The function we’re applying is my_func, which divided the object by 100 Activity A10.3: Use lapply to turn columns 6 to 10 (swfc_16[,grep(“Perc”, c(6:10))]) into character columns, from factor columns. "],
["maps.html", "Chapter 11 Maps 11.1 Loading in geospatial data 11.2 Coordinate systems 11.3 Transforming mapping data 11.4 Point maps 11.5 Chloropleth maps", " Chapter 11 Maps Maps in R are best plotted using ggplot - which is good, because we already know how to use that! However, the new thing about maps is the sort of data we’ll be using - as well as having data about certain variables, this data has a location attached to it too. First, we need to load in the packages we need. We’ll need the following packages: tidyverse, as this contains ggplot2 for plotting and dplyr for data manipulation rgdal, a package for loading in spatial data broom, a package for converting spatial data into dataframes to be plotted in ggplot2 Activity A11.1: Install rgdal Install broom Use library() to load tidyverse, rgdal, and broom 11.1 Loading in geospatial data Geospatial data comes in three forms: Polygons (shapes) Lines Points Polygons and points are the most common (geospatial line data only really features when relating to travel infrastructure or people movements), so we’ll focus on these two. Point, polygon, and line data can come in a number of different data formats, but the msot common is a ‘shapefile’ with a .shp suffix. We can use the rgdal library to load in shapefiles. Firstly, we’re going to load the names of location of major UK cities using the readOGR function. Make sure you have the shapefiles located in a folder called shps within your data folder first. cities &lt;- &quot;data/SHPs/england_cities.shp&quot; %&gt;% readOGR() ## OGR data source with driver: ESRI Shapefile ## Source: &quot;C:\\Users\\tfranklin\\OneDrive - Department for Education\\Documents\\Data Outputs\\Git Repository\\r-training-course\\data\\SHPs\\england_cities.shp&quot;, layer: &quot;england_cities&quot; ## with 48 features ## It has 2 fields Plotted, the cities look like this: …which looks vaguely like the UK! You’ll see cities is a SpatialPointsDataFrame class object. The essentially means it’s a dataframe with spatial data attached. Activity A11.2: Click the blue circle to the left of cities to open up the object. You’ll see there’s an attribute within cities called data, and another attribute called coords. Access these by typing cities@ and then whichever of the attributes you want to view. We can also use readOGR to load in polygon data. The file we’re going to use is one containing the boundaries of Local Authorities (LAs) in England, called England_LA_2016.shp. england &lt;- &quot;data/SHPs/England_LA_2016.shp&quot; %&gt;% readOGR() ## OGR data source with driver: ESRI Shapefile ## Source: &quot;C:\\Users\\tfranklin\\OneDrive - Department for Education\\Documents\\Data Outputs\\Git Repository\\r-training-course\\data\\SHPs\\England_LA_2016.shp&quot;, layer: &quot;England_LA_2016&quot; ## with 152 features ## It has 8 fields This is a SpatialPolygonsDataFrame, which makes sense! However, if we plot the LAs alongside the cities, the don’t match up. ## integer(0) What we have here is all of the city points plotted down in the bottom lefthand corner (although you can only see one) over the LA map. This is because the cities data and the LA data use different ‘coordinate systems’. 11.2 Coordinate systems At their most basic level, coordinates are just numbers that represent a location, where all the points within that set follow the same form. With that in mind, we can use different sets of numbers, or systems, to represent the location of a point. There are a lot of coordinate systems that are used in mapping, but the most common that you’ll come across when mapping UK data are: WGS84 (EPSG4326): This is the standard Latitude and Longitude coordinate system to map global data, developed in 1984. It makes the assumption that the earth is a perfect sphere (it’s actually a bit elliptical - wider at the sides), and Longitude (on the x axis) goes between -180 and 180 (degrees), with 0 being the Meridian Line in Greenwich, London. Latitude (on the y axis) again goes between -180 and 180, with 0 on the Equator. OSGB36 (EPSG27700): This is a grid system, with units in metres, specific to the UK. It’s origin is about 100km west of Lands End, roughly level with the most southerly point of the mainland Britain, Lizard Point. It assumes that the British Isles are on a completely flat plane (which of course they aren’t). On the x axis are Eastings and on the y axis are Northings. The largest coordinate value is (800000,1300000). Tip: The EPSG codes are codees from the now defunct European Petroleum Survey Group, and are a common code for different coordinate systems. These are the codes that we’ll use to change the coordinate systems. For more information on codes click here. Let’s check which coordinate systems cities and england are on. #Find out the coordinate system of cities cities@proj4string ## CRS arguments: ## +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 So, cities is on WGS84 - we can see from its datum (origin) attribute. #Find out the coordinate system of england england@proj4string ## CRS arguments: ## +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 ## +y_0=-100000 +datum=OSGB36 +units=m +no_defs +ellps=airy ## +towgs84=446.448,-125.157,542.060,0.1502,0.2470,0.8421,-20.4894 So, england is on OSGB36 - again we can see from its datum attribute. Therefore, we need to translate one of the coordinate systems into the other. We’re going to convert cities into the OSGB36 coordinate system, because it’s a bit more of an intuitive system to use, using a grid in metres instead of degrees. cities &lt;- cities %&gt;% spTransform(CRS(&quot;+init=epsg:27700&quot;)) Let’s break this down: cities is our object name, and the first ingredient in our ‘recipe’ using pipes. We’re essentially updating cities. spTransform is a function for transforming spatial objects’ coordinate systems CRS stands for ‘Coordinate Reference System’ - this takes an argument which is a string containing the EPSG code of the coordinate system we want to convert to, which in this instance is EPSG27700 Activity A11.1: After you’ve run the code above, recheck which coordinate system cities is on. Now if we replot cities and england, we’ll see they line up more as we’d expect. ## integer(0) 11.3 Transforming mapping data As mentioned, we’re going to be using ggplot to plot the maps. However, ggplot takes dataframes, and currently we have spatial dataframes, so that’s not going to fly. What we need to do is convert our spatial dataframes into normal dataframes. There are two methods for this: For point data we can just convert it straight to a normal dataframe, and select the coordinates and any other required columns (e.g. labels) For polygon data we need to use a broom function called tidy, which breaks a polygon up into a series of lines, and creates a dataframe where each row is a coordinate of the start of one line and the stop of another, as well as a column detailing which group (in this instance a Local Authority) it’s part of Let’s deal with the point data first. cities_df &lt;- cities %&gt;% #Create a dataframe (df) version of cities data.frame() cities_df &lt;- cities %&gt;% #Create a dataframe (df) version of cities data.frame() %&gt;% select(city=City, easting = coords.x1, northing = coords.x2) Which creates something that looks like this: ## city easting northing ## 1 Bath 374654.4 164546.7 ## 2 Birmingham 405758.2 285421.0 ## 3 Bradford 416570.4 431915.0 ## 4 Brighton 531128.8 104856.1 ## 5 Bristol 359560.8 172496.5 ## 6 Cambridge 544754.9 257863.3 Activity A11.2: We need to do a bit of cleaning on this dataframe. Select only three columns, rename coords.x1 as easting and coords.x2 as northing. With a polygon object, we can’t just use the data.frame function, because unlike a point object, there are multiple coordinates associated with each item in the data slot. So this is where we’re going to use tidy. england_df &lt;- england %&gt;% tidy() %&gt;% as.tbl() #We need this function to explicitly specify that that output is a dataframe Which leaves us with something that looks like this: ## # A tibble: 6 x 7 ## long lat order hole piece group id ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;lgl&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; ## 1 447097. 537152. 1 FALSE 1 0.1 0 ## 2 447229. 537033. 2 FALSE 1 0.1 0 ## 3 447281. 537120. 3 FALSE 1 0.1 0 ## 4 447378. 537095. 4 FALSE 1 0.1 0 ## 5 447455. 537024. 5 FALSE 1 0.1 0 ## 6 447551. 537078. 6 FALSE 1 0.1 0 There are a few things to notice about this dataframe: The tidy function, when applied to spatial objects, automatically names the coordinate columns long and lat. In this instance long is actually easting and lat is actually northing - we’ll change the names in a minute. There are three defunct columns for our purposes: order, hole, and piece There’s no identifier for a Local Authority (name or code), which is present in the data slot of england. This has been replaced by the id column - each polygon’s points are identified by a unique number in that column. When we plot this data, ggplot2 will initially plot each of these polygons as one continuous line. This means that if one polygon does not start (indicated by the order column) at different coordinates to where the previous polygon finished, then a straight line across a polygon will appear (like the example below), connecting the two points. The group column prevents this from happening by not linking polygons in different groups. ggplot()+ geom_polygon(data=england_df, aes(long,lat), col=&quot;grey&quot;, fill=NA) + coord_equal() + theme_minimal() + theme(axis.line=element_blank(), axis.text.x=element_blank(), axis.text.y=element_blank(), axis.ticks=element_blank(), axis.title.x=element_blank(), axis.title.y=element_blank(), panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank(), legend.title=element_blank()) So, we need to create another dataframe which has all the data from england as well as an id column, to match to the dataframe that we’ve just created. england_data &lt;- england@data %&gt;% cbind(england_df %&gt;% select(id) %&gt;% unique()) #Here we&#39;re binding the unique values from the id column in england_df to the data slot from england - the order remains the same which is why we can just bind them This dataframe looks like this: ## LA15CD LA15NM LA_Code RSC_Code ## 0 E06000001 Hartlepool 805 5 ## 1 E06000002 Middlesbrough 806 5 ## 2 E06000003 Redcar and Cleveland 807 5 ## 3 E06000004 Stockton-on-Tees 808 5 ## 4 E06000005 Darlington 841 5 ## 5 E06000006 Halton 876 8 ## RSC_Name Reg_Code RGN15CD RGN15NM id ## 0 North 9 E12000001 North East 0 ## 1 North 9 E12000001 North East 1 ## 2 North 9 E12000001 North East 2 ## 3 North 9 E12000001 North East 3 ## 4 North 9 E12000001 North East 4 ## 5 Lancashire &amp; West Yorkshire 8 E12000002 North West 5 Activity A11.3: Match england_data into england_df, using id and an inner join. Keep the following columns using select: long (renaming it easting), lat (renaming it northing), LA15NM, LA15CD, and group. The data is now in a format where we can get plotting! 11.4 Point maps Point maps are useful where you want to show the location of entities with a single location, and attributes/values associated with that entity. In this example we’re going to map all schools within the Local Authority of Wiltshire, along with their phase and size. First, we want to load in the data we’re going to be using. We’re going to load in the shapefile called wiltshire_schools and transform it in one fell swoop. wiltshire_schools_df &lt;- &quot;data/shps/wiltshire_schools.shp&quot; %&gt;% readOGR() %&gt;% data.frame() %&gt;% select(easting = coords.x1, northing = coords.x2, LAEst:P_FT_T) ## OGR data source with driver: ESRI Shapefile ## Source: &quot;C:\\Users\\tfranklin\\OneDrive - Department for Education\\Documents\\Data Outputs\\Git Repository\\r-training-course\\data\\SHPs\\wiltshire_schools.shp&quot;, layer: &quot;wiltshire_schools&quot; ## with 231 features ## It has 53 fields Tip: If you look at the dataframe, you’ll see the column names have been abbreviated - this is because shapefiles are limited to 8 characters for column names. However, we can refer to swfc_16_init to work out what the column names are. We can now finally plot some data! ggplot() + geom_point(data=wiltshire_schools_df,aes(easting,northing)) So, we’ve plotted some data, but it doesn’t look overly map like. Let’s break down what we’ve written first, and then we’ll make it look more like a map: ggplot(): The standard function, but notice here it has no arguments. This is because ggplot2 also allows you to specify your data and aesthetics from within the type of plot you’re displaying. This is really useful when you’re plotting different types of graphs from different data sources on the same coordinate system. geom_point: We’ve seen this before with scatter plots - it’s the same thing applied to spatial point data. data=wiltshire_schools_df: This is the data we’re using, the quirk here is that when specifying data within the type of plot as opposed to from within ggplot we need to explicitly specify the name of the argument, with data=. aes(easting,northing): Standard aesthetics, plotting the Easting and Northing of each plot Now let’s makr it look more like a map. The first thing we can do is make the coordinates an equal scale (currently the x-axis is more stretched than the y-axis), and get rid of the grey background, the grid lines, and then axis labels. ggplot() + geom_point(data=wiltshire_schools_df,aes(easting,northing)) + coord_equal() + theme(axis.line=element_blank(), axis.text=element_blank(), axis.ticks=element_blank(), axis.title=element_blank(), panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank()) There’s a lot to specify in the theme function, but once you’ve written it once you can copy it again and again (or even write a function to make it more concise/robust!). That’s looking more map-like! What would really help is the border of Wiltshire. To do that we need to get a subset of england_df which only contains coordinates which bound Wiltshire: wiltshire_df &lt;- england_df %&gt;% filter(LA15NM == &quot;Wiltshire&quot;) We can then add a polygon to our map: ggplot() + geom_polygon(data=wiltshire_df,aes(easting,northing),col=&quot;grey&quot;,fill=NA) + geom_point(data=wiltshire_schools_df,aes(easting,northing)) + coord_equal() + theme(axis.line=element_blank(), axis.text=element_blank(), axis.ticks=element_blank(), axis.title=element_blank(), panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank(), legend.title = element_blank()) That’s more like it! Let’s break down what we’ve got: geom_polygon: This plots a polygon data=wiltshire_df,aes(easting,northing): We’ve seen this format before col=“grey”,fill=NA: We want a grey outline and no fill colour Notice how we plot the polygon first - this is because ggplot2 builds up layers on top of each other, so we want the points on top of the polygon. The final thing we need to do is add some attributes to the points. This uses the same arguments we’ve used in plotting graphs. Activity A11.4: Use col= and size= in the aesthetics in geom_point to detail the phase of the school (column name Sch_P in wiltshire_schools_df) and the size of the school’s workforce (column name T_W_H in wiltshire_schools_df) Tip: Add in legend.title = element_blank() to get rid of the legend title and legend.key = element_rect(fill=NA) to get rid of the grey backgrounds behind the legen - both just make it look a bit more professional! 11.5 Chloropleth maps The other type of map that we’re going to look at are chloropleth maps. Chloropleth maps are maps of multiple polygons with each polygon filled in with a certain colour/hatching depending on a certain attribute/value. A chloropleth map uses similar code to a point map. We’re going to plot a map which has the average total workforce for schools in each Local Authority on it. However, the first thing we need to do is to attach data on the average school workforce for each Local Authority from swfc_16 to england_df. england_df &lt;- england_df %&gt;% inner_join(swfc_16 %&gt;% group_by(LA_Name) %&gt;% summarise(ave_tot_workforce = mean(Tot_Workforce_HC,na.rm=TRUE)),by=c(&quot;LA15NM&quot;=&quot;LA_Name&quot;)) ## Warning: Column `LA15NM`/`LA_Name` joining factors with different levels, ## coercing to character vector This gives us a dataframe that looks like this: ## # A tibble: 6 x 6 ## easting northing group LA15CD LA15NM ave_tot_workforce ## &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 447097. 537152. 0.1 E06000001 Hartlepool 67.2 ## 2 447229. 537033. 0.1 E06000001 Hartlepool 67.2 ## 3 447281. 537120. 0.1 E06000001 Hartlepool 67.2 ## 4 447378. 537095. 0.1 E06000001 Hartlepool 67.2 ## 5 447455. 537024. 0.1 E06000001 Hartlepool 67.2 ## 6 447551. 537078. 0.1 E06000001 Hartlepool 67.2 We can plot a simple chloropleth: ggplot()+ geom_polygon(data=england_df, aes(easting,northing,group=group,fill=ave_tot_workforce), col=&quot;grey&quot;) + coord_equal() + theme(axis.line=element_blank(), axis.text=element_blank(), axis.ticks=element_blank(), axis.title=element_blank(), panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank(), legend.title = element_blank()) The two key differences to a point map are: The use of the group argument, to remove lines across polygons to connect them all The use of the fill argument with the ave_tot_workforce, which fills each Local Authority polygon with a colour corresponding to its value The key thing that our chloropleth map is currently missing is some sort of reference to actual locations. However, we’ve got our city point data which we can add in, along with text labels. We have to build this up in two stages, so the first thing we’ll add in are the points: ggplot()+ geom_polygon(data=england_df, aes(easting,northing,group=group,fill=ave_tot_workforce), col=&quot;grey&quot;) + geom_point(data=cities_df, aes(easting,northing), col=&quot;red&quot;) + coord_equal() + theme(axis.line=element_blank(), axis.text=element_blank(), axis.ticks=element_blank(), axis.title=element_blank(), panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank(), legend.title = element_blank()) So we’ve plotted the location of the cities, using geom_point, which we’ve used before. To add the labels we need to use a new function however, called geom_text. ggplot()+ geom_polygon(data=england_df, aes(easting,northing,group=group,fill=ave_tot_workforce), col=&quot;grey&quot;) + geom_point(data=cities_df, aes(easting,northing), col=&quot;red&quot;) + geom_text(data=cities_df, aes(easting,northing,label=city), check_overlap = TRUE, col=&quot;red&quot;, hjust = 1.1, vjust=0.3) + coord_equal() + theme(axis.line=element_blank(), axis.text=element_blank(), axis.ticks=element_blank(), axis.title=element_blank(), panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank(), legend.title = element_blank()) Let’s break geom_text down: We’ve seen data= and the first two arguments of aes before label=city adds a text label of a certain value to the coordinates detailed in easting and northing check_overlap = TRUE checks if a each label overlaps with a previous label, and if it does, it won’t plot it. For example, ‘Bristol’ overlaps with ‘Bath’, so because Bristol comes after Bath, it isn’t plotted. col = “red” makes the text colour red hjust = 1.1 and vjust=0.3 make adjustments to the horizontal and vertical position of the label in relation to the point. This has been done so that the label doesn’t sit right on top of the point. "],
["r-markdown.html", "Chapter 12 R Markdown 12.1 Text 12.2 Code 12.3 Multiple Reports", " Chapter 12 R Markdown We now know how to do a range of data analysis, as well as producing a lot of different visualisations. Now we need to know how to compile all of that into a report, and automatically produce that report. The has numerous benefits over the traditional Excel and Word approach to writing out analysis: Faster, once the template is written More robust - errors are less likely to occur, particuarly when copying from Excel to Word Can be updated immediately if/when data changes There are two elements to R Markdown, the text (which has a number of ways of formatting it) and the code (which can be displayed and included in different ways). We’ll look at both of these, but first, we need to open an R Markdown file: Go to File Go to New File Click on R Markdown A new tab will open up in the script pane - have a look at it as it contains an example R Markdown template in the top right hand corner of the script pane click on the arrow next to Knit and click on ‘Knit to HTML’ Save the R Markdown file in the ‘2_code’ folder The code will run and the output will pop up upon completion Compare this to the input file The output file will have saved in the ‘2_code’ folder - it shouldn’t output to here, but we’ll sort that later This is how you generate an R Markdown document. When you make changes to it from now on, you won’t have to specify the name and save location every time you knit it. Tip: HTML is the preferable output - it is more versatile in designs and can include interactive elements, however if you want to you can also output to Word, and if you have additional software installed (called LaTex and pronounced ‘lay-tec’) you can output straight to PDF. 12.1 Text We can see from the template above that there are a range of ways of formatting text to render it to look good in a report. First of all, headings. Headings are generated by sequential hashes - one hash is the largest heading, and six hashes is the smallest heading. These can be used to create a series of sub-headings in documents. # Heading 1 Heading 1 ## Heading 2 Heading 2 ### Heading 3 Heading 3 #### Heading 4 Heading 4 Activity A10.3: Add some headings and change the sizes of some of the headings in the template. Run the R Markdown document and see how they output. Another useful formatting feature are lists. These can either be ‘ordered’ (1, 2, 3 or a, b, c) or ‘unordered’ (bullet points). The two examples below how to produce ordered and unordered lists, but there are three important things to remember with lists: There must be a clear line in between the end of the prose above the list and the list itself There must be a space between the character that denotes the list item and the prose There must be a clear line in between the end of the list and the prose below An unordered list: * Thing 1 * Thing 2 * Thing 3 An unordered list: Thing 1 Thing 2 Thing 3 An ordered list: 1. Thing 1 2. Thing 2 3. Thing 3 An ordered list: Thing 1 Thing 2 Thing 3 Activity A10.3: Add some headings and change the sizes of some of the headings in the template. Run the R Markdown document and see how they output. The final formatting feature to demonstrate in this chapter are creating hyperlinks. To create the hyperlink, the text to be made a link is bound in square brackets, and the address of the link comes immediately afterwards bound by brackets: A [link](http://www.yourlinkhere.com) A link Tip: There is loads more functionality in R Markdown for different formatting - just Google it! 12.2 Code However, the text edits we can make to R Markdown documents are only half of the story - the beauty of it is that you can merge text and the outputs of code. So how do we include code? Code in R Markdown is written in ‘chunks’. Chunks are written in the form below and appear in an R Markdown in a slightly grey section: ```{r} print(’hello world) ``` Let’s break that down: 3 grave accents signify the start of the code chunk {} signify the metadata that goes with the chunk - more on this in a minute Inside the curly brackets, the r signifies the programming language we’re going to be writing in We’ve then got some code - as many lines as you want with whatever outputs you want 3 grave accents close of the code chunk Here’s what it looks like in an output: print(&#39;hello world&#39;) [1] &quot;hello world&quot; Activity: Write this out and run it in your R Markdown documents. Sometimes we’ll want to include this code with outputs, sometimes only outputs, sometimes only code. We can control this using effect messages. Effect messages appear after the r within the curly brackets: ```{r, effect_message_here} With an effect message you will specify whether that effect is true or false. The list below shows the effect messages that are likely to be useful - the default for all of the message below is true. eval = FALSE: Prints the code but not the results warning = FALSE: Hides any warnings that come with the code echo = FALSE: Hides the code but prints the results include = FALSE: Hides code and doesn’t print any results (good for setup sections which load in libraries and data) message = FALSE: Removes any other messages that come with an output (this is the least common of this set) Tip: After r in a code chunk include a new for that chunk - it makes navigating easier, which can be done by clicking in the bottom lefthand corner of the script pane. You can’t have multiple sections with the same name though. Activity: Run the code below five times. The first four timed include one of eval, warning/span&gt;, echo/span&gt;, and include/span&gt; in the top of the code chunk, and for the fifth time include whatever combination of effect messages you would need to output this graph for a customer who was only interested in the outputs. ggplot(swfc_16,aes(Tot_Workforce_HC,Tot_Teachers_HC)) + geom_point() The final useful code chunk technique is ‘inline code’. Often we’ll want to calculate values from the data and report them in the text. Traditionally, if we were using Word and Excel, we’d calculate this in Excel, remember the number, and then type it up in Word - think of the things that could go wrong with that! We could get the number wrong when trying to remember it or we could type it wrong. R Markdown allows you to embed values in the text, so that it’s directly calculated from the data. To include an inline piece of code, write this: `r object_name` Activity: In your R Markdown file, write a code chunk that calculates the average total number of FTE Teaching Assistants (Tot_TAs_FTE) and call it ave_tot_tas_fte. Then write a sentence that states what the average total FTE of Teaching Assistants in each school is. Run the code and look at the output. 12.3 Multiple Reports Remember we wrote an lapply function to produce numerous graph for each different region? We can do the same for R Markdown reports to produce the same report for different entities, and whilst it’s got a few more steps than the lapply approach, the premise is the same. We’ll nned two file: The first is the actual R Markdown file, with a variable in it which will allow us to filter data to produce it for specific entities The second is an R script, which will iterate over the categories and produce a Markdown output for each of them. We’ll produce the R Markdown first. Activity: Open a new R Markdown and do the following: Remove the template in there currently Save the R Markdown file in the code file, and call it ‘region_factsheet’ Create a heading which has an inline code chunk with the variable region_name (this doesn’t currently exist - this is the object name that will be the iterand) Write a code chunk which loads in the tidyverse library and the School Workforce Census data - the code and outputs should be hidden (when you’re loading the data you’ll need data/swfc_2016_machine_readable.csv, because the R Markdown file is saved in the 2_code folder, so the says ‘go back up one step’) Write another code chunk that creates a numeric object (use as.numeric()) which is the number of schools in the region (you might have to trial this with an actual region before replacing it with region_name) Write a sentence which states the number of schools within the region, using region_name and your object from stage 5 in inline code within the sentence Write the code to plot the distribution of the school size within that region, using the code below ggplot(swfc_16 %&gt;% filter(Government_Office_Region_Name == region_name), aes(Tot_Workforce_HC)) + geom_histogram() + ggtitle(paste0(&#39;Distribution of school size in &#39;,region_name)) Next, we’ll produce the R script which will create each of the factsheets. Activity: Open a new R script and do the following: Load the tidyverse and rmarkdown libraries Load in the School Workforce Census Create an object which contains all the different levels of Government_Office_Region_Name called regions Create an lapply: The element which is going to have the function applied to each element of it is regions The object name in function() is region_name - this is the thing we want to change each time in the R Markdown file (look back at the R Markdown file you’ve just created if needs be) The function we’re going to apply is the render() function from the markdown package, it uses the code below render(&#39;2_code/region_factsheet.Rmd&#39;, #This is the name of the R Markdown file we want to produce an output from output_file = paste0(region_name,&quot;.html&quot;), #This is what the name of the output file will be - the region name and .html output_dir = &#39;outputs&#39;)) #They will be stored in the outputs directory RUN IT! And that’s it - hopefully by completing this course you’ve got a good introduction to the power of R! "]
]
