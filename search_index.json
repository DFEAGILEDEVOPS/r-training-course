[
["index.html", "DfE R training Preface", " DfE R training Preface This resource is an introduction to the R programming language. It can be used as standalone learning tool, or as part of training sessions. It takes you through from the first steps of opening RStudio through using it for visualisations such as graphs and maps - basically an introduction to using R for simple but effective data management, manipulation, calculations, and visualisation. It does however work on the assumption that R and R Studio are already installed. The format of the training is as follows: Text describing what we will be doing Code showing what needs typing in: print(&quot;Hello world&quot;) Activities for you to do to put your learning to the test Activity A0.1: Write a line of code that prints the string “Hello world” Little tips to make writing code easier Tip: R is great tool "],
["why-r.html", "Chapter 1 Why R? 1.1 Current Workflow 1.2 The bottom line 1.3 R is the answer 1.4 But what is R? 1.5 Should I stop using all other tools?", " Chapter 1 Why R? 1.1 Current Workflow A typical analytical workflow in our department might involve SQL, Excel and Word. Typical steps might be: Query a database with SQL code using SQL Server Management Studio QA this code Copy and paste the output into Excel Process the data in Excel Produce outputs (tables, plots, etc) manually in Excel QA your Excel file(s) Copy and paste outputs into a Word document QA the Word document You notice an error Debug somehow (go back to step 1?) There are three main reasons why this isn’t ideal. It’s: got a high chance of producing errors difficult to reproduce your work (what order were the steps in your workflow?) time consuming (many steps, lots of wasted time) So, let’s discuss what we mean by ‘errors’. This is mostly a problem with spreadsheets and moving data in and out of them. You: might alter data without realising could copy-paste data or formulae incorrectly with little record of what steps you took (e.g. this high profile case) might not realise how frequent these errors are until they get embarrassing In terms of reproducibility, you don’t have a record of the order of doing things and therefore it’s not easy to backtrack on mistakes. A lot of documentation and commenting is required within and across multiple files to ensure that the workflow can be replicated. Typically, this is not always the case. If you write reproducible code, it may also be easier to automate it. This in turn can help free-up time for other, perhaps less trivial, tasks. For example, the Reproducible Analytical Pipeline (RAP) approach helps reduce error and speed up the process of producing official statistics. Obviously the process takes time because you have to copy-paste values from place to place and perform quality assurance across all the files in your workflow. But there’s also the time needed to remember how you did the analysis when you’re asked to make changes long after you remember how the process works. 1.2 The bottom line Our analytical work has a direct impact on policy decisions and therefore it affects young people, parents, learners, schools, teachers and many others. Above all humans cannot be trusted. Let’s minimise the chance of errors, speed things up and make it easy on our future selves by minimising the chance of doing it wrong in the first place. This means breaking away from spreadsheet addiction. 1.3 R is the answer What might an optimal analytical workflow look like in R then? Run your code This is simple. R is end-to-end: you can get data in at one end from files or a database and pump it out the other in a report or app, while also having automated testing built in. All from the same script. You also have the opportunity to more easily version your work using tools such as Git and GitHub. 1.4 But what is R? R is a just another tool for data analysis, in the same way that Excel and SQL are tools for data analysis. Put simply, R lets you read, wrangle and analyse data and create outputs such as graphics, documents and interactive apps. R is a coding language, which means you use it to write instructions for the computer to perform. This allows for fine control of what you want to do. You can think of R as a place where data is abstracted away and the instructions are brought to the forefront, whereas spreadsheets are where data is at the forefront and the instructions are abstracted away (I heard this somewhere but can’t remember the source; let me know). RStudio is simply a very useful interface for R that provides a whole bunch of useful bells and whistles. What’s great about R? It’s: free available on our work laptops via Software Center open-source and cross-platform (you can download it for Windows, Mac and Linux machines) established and has many high-quality extensions available (‘packages’) has a big and active community, both in the department (e.g. Coffee &amp; Coding) and online (e.g. the RStudio Community) got a lot of in-built help files got a wealth of articles and help online (e.g. the R bloggers feed and via StackOverflow) got excellent statistical and graphics capabilities in particular the suite of RStudio tools make documentation, teaching and dissemination much easier I could go on. 1.5 Should I stop using all other tools? R is not always the answer. We’re not telling you that we must do things in any particular way. For example, you have an urgent request for the minister due in five minutes and you don’t have the experience to do it in R. Excel may be good enough. That’s absolutely fine. The argument here is that we should move towards a more reproducible model, so that when the minister comes back wanting to tweak your calculation you can be confident that you can remember what you did and how you did it. "],
["getting-started-with-rstudio.html", "Chapter 2 Getting Started with RStudio 2.1 Opening R Studio 2.2 R Studio Layout 2.3 Setting up a project", " Chapter 2 Getting Started with RStudio 2.1 Opening R Studio First thing, open up R Studio! Either find the RStudio icon on your desktop/start menu, or search for it in the start menu search (this is assuming you are using a Windows computer): 2.2 R Studio Layout Clink on it and the R Studio interface will open, and will look like this: At this stage, there are three panes in an R Studio window: Left Panel: The console - this shows you which code you have run and any outputs you might specify, and also allows you to run lines of code which you don’t need to save (e.g. to remove an object) Top right: The environment - this is where R Studio shows you which objects (stuff - data tables, strings, numbers, personalised functions) you have available *Bottom right: Everything else - the help function, the place to view graphs, and the place to view which files you have available 2.3 Setting up a project Analysis in R is carried out in ‘projects’. A ‘project’ creates an space which contains all of the inputs, code, and outputs that relate to the analysis. Activity A3.1: Create a new project: Click on File Click on New Project Click on New Directory Click on Empty Project In ‘Directory name’ type R_training In ‘Create project as subdirectory of’ select a folder that you commonly use, like Documents Click ‘Create project’ Click File Click New File Click R Script Great, we’ve now created a project - all pieces of analysis should start with a project. We now need to put some stuff in it. Activity A3.2: Set up your folder structure: Open up your file explorer and navigate to the directory (folder) you just created in R Studio Create the following folders: R Data Outputs Misc Move the data you’ve been sent into Data. We can now view this environment within R Studio - click on ‘Files’ in the bottom right console. "],
["data.html", "Chapter 3 Data", " Chapter 3 Data We’re going to use data from the Department for Education’s School Workforce Census. This is an annual census of teachers in England that’s collected every November and published in the following July. We’ll use two CSV (Comma-Separated Values) files that contain simplified versions of the original data. One has data on headcounts and the other has data for hours worked (full-time equivalent, or FTE). You’ll download these to your Project folder, which you set up in the previous chapter. Activity A2.1: Download the data sets Get the headcount data set Unzip the folder and move the CSV file inside to the ‘Data’ subfolder of your Project folder Repeat steps 1 and 2 for the hours worked (FTE) data "],
["general-coding.html", "Chapter 4 General Coding 4.1 Objects 4.2 Comments", " Chapter 4 General Coding 4.1 Objects Objects are any ‘thing’ that you create in R. They’re shown in your Environment. There are a huge number of objects in R. The following illstrates a numer of the core object types: my_string &lt;- &#39;DfE&#39; my_number &lt;- 2017 my_boolean &lt;- TRUE my_vector &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) my_dataframe &lt;- data.frame(var1 = c(1,2,3,4,5), var2 = c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;,&quot;e&quot;)) my_list &lt;- list(my_string,my_number,my_boolean, my_vector, my_dataframe) Tip: When naming objects it is useful to do the following: Make the names meaningful but short e.g. we could call School Workforce Census Table swfc. Stick to one convention. The standard for R is snake_case. See here for further details on R Style Guide. To run that code you will first need to create a new script File &gt; New File &gt; R Script. You can then run line by line by having your cursor on that line or highlight chunks and then doing one of the following: Press CTRL + ENTER Click ‘Run’ in the top right hand corner of the script window Tip: Double click highlights term Triple click highlights line Quadruple click highlights entire script The &lt;- sign is called a get sign. It ‘gets’ the output from the right hand side and attributes it to the object name. Tip: ALT + - is a shortcut to inputting the get sign. Activity A3.3: What does typeof(OBJECT NAME) do? Activity A3.4: Now save your work in the R folder! Writing the following code will remove a specified object: rm(object_name) Writing the following code will remove all objects: rm(list = ls()) Activity A3.5: Arguments are the bits of code inside brackets, and if there are multiple arguments they’re separated by commas. Explain the what the argument inside the second rm in the code above does. 4.2 Comments Activity A3.6: Type 1+1 and run it, what comes up in the console? Put a # in front of 1+1, what comes up in the console? Comments are really important for annotating code, so that you and others know exactly what the code does and why. Here we add a description of what setwd() does: #Remove all objects rm(list = ls()) Tip: CTRL + SHIFT + C comments multiple lines at once CTRL + SHIFT + R creates a section, which you can jump between using the dropdown list in the bottom left corner of the script window "],
["base-r.html", "Chapter 5 Base R 5.1 Loading in data 5.2 Basic dataframe functions 5.3 Selecting certain columns/removing columns 5.4 Conditional Selections 5.5 Altering data in dataframes 5.6 Writing data", " Chapter 5 Base R R comes with a number of functions that allow you to maniuplate, summarise and analyse data. Collectively these are known as Base R. This chapter summarises some of the core functions for manipulating data in base R. 5.1 Loading in data The most common process to load in data is to load in a CSV file. #Load in data swfc_16_init &lt;- read.csv(&quot;data/SWFC_2016_Machine_Readable.csv&quot;) swfc_16 &lt;- swfc_16_init Tip: Load in and create and initial, raw version of the file, and never do anything to that object. This means if you muck anything up, you’ll always have a clean dataset to start again from. This is particularly important when loading in big dataframes, such as those from SQL. 5.2 Basic dataframe functions There are a number of functions which can be used to gain a summary of data: #Basic dataframe exploration functions summary(swfc_16) #Get a summary of each variable Tip: This worksheet is built using an add on to R called R Markdown, which integrates code, text, and images. We’ll come on to how to create R Markdown documents later, but for now, the box below with a white background and grey border is an output from the above code as it renders in R Markdown. Remember this, it will appear a lot in the worksheet. ## LA_Number Establishment_Number LAEstab_2016 ## Min. :201.0 Min. :1000 Min. :2013614 ## 1st Qu.:371.0 1st Qu.:2115 1st Qu.:3712144 ## Median :850.0 Median :3001 Median :8502761 ## Mean :697.6 Mean :3133 Mean :6979196 ## 3rd Qu.:891.0 3rd Qu.:3605 3rd Qu.:8912352 ## Max. :938.0 Max. :7750 Max. :9387022 ## ## LA_Name URN ## Lancashire : 632 Min. :100000 ## Kent : 581 1st Qu.:110587 ## Essex : 556 Median :120528 ## Hertfordshire: 535 Mean :122340 ## Hampshire : 531 3rd Qu.:137029 ## Birmingham : 447 Max. :143768 ## (Other) :18631 ## School_Name ## St Joseph&#39;s Catholic Primary School : 57 ## St Mary&#39;s Catholic Primary School : 41 ## St Anne&#39;s Catholic Primary School : 20 ## St Patrick&#39;s Catholic Primary School: 20 ## Holy Family Catholic Primary School : 19 ## St Peter&#39;s Catholic Primary School : 18 ## (Other) :21738 head(swfc_16) #Get the top 6 rows ## LA_Number Establishment_Number LAEstab_2016 LA_Name URN ## 1 331 4004 3314004 Coventry 141104 ## 2 332 2010 3322010 Dudley 103774 ## 3 330 4010 3304010 Birmingham 139788 ## 4 332 2012 3322012 Dudley 103775 ## 5 332 2043 3322043 Dudley 103781 ## 6 210 1025 2101025 Southwark 100768 ## School_Name ## 1 Seva School ## 2 Kates Hill Community Primary School ## 3 Waverley Studio College ## 4 Northfield Road Primary School ## 5 Dawley Brook Primary School ## 6 Ann Bernadt Nursery School tail(swfc_16) #Get the bottom 6 rows ## LA_Number Establishment_Number LAEstab_2016 LA_Name URN ## 21908 855 2092 8552092 Leicestershire 143250 ## 21909 831 2424 8312424 Derby 112728 ## 21910 882 2105 8822105 Southend-on-Sea 143341 ## 21911 936 2269 9362269 Surrey 142433 ## 21912 931 2561 9312561 Oxfordshire 137992 ## 21913 831 1009 8311009 Derby 112475 ## School_Name ## 21908 Newcroft Primary Academy ## 21909 Pear Tree Infant School ## 21910 Thorpe Greenways Infant School ## 21911 Lightwater Village School ## 21912 Faringdon Infant School ## 21913 Walbrook Nursery School colnames(swfc_16) #Get list of column names ## [1] &quot;LA_Number&quot; ## [2] &quot;Establishment_Number&quot; ## [3] &quot;LAEstab_2016&quot; ## [4] &quot;LA_Name&quot; ## [5] &quot;URN&quot; ## [6] &quot;School_Name&quot; ## [7] &quot;School_Type_Description&quot; ## [8] &quot;School_Type&quot; ## [9] &quot;School_Phase&quot; ## [10] &quot;Religious_Character&quot; ## [11] &quot;Government_Office_Region_Name&quot; ## [12] &quot;Parliamentary_Constituency&quot; ## [13] &quot;LA_District&quot; ## [14] &quot;Ward&quot; ## [15] &quot;StatutoryLowAge&quot; ## [16] &quot;StatutoryHighAge&quot; ## [17] &quot;Tot_Workforce_HC&quot; ## [18] &quot;Tot_Classroom_Teachers_HC&quot; ## [19] &quot;Tot_Teachers_Leadership_HC&quot; ## [20] &quot;Tot_Teachers_HC&quot; ## [21] &quot;Tot_TAs_HC&quot; ## [22] &quot;Tot_NonClassroom_Support_Staff_Exc_Aux_Staff_HC&quot; ## [23] &quot;Tot_Auxiliary_Staff_HC&quot; ## [24] &quot;Perc_PT_Teaching_Staff_&quot; ## [25] &quot;Tot_Workforce_FTE&quot; ## [26] &quot;Tot_Classroom_Teachers_FTE&quot; ## [27] &quot;Tot_Teachers_Leadership_FTE&quot; ## [28] &quot;Tot_Teachers_FTE&quot; ## [29] &quot;Tot_TAs_FTE&quot; ## [30] &quot;Tot_NonClassroom_Support_Staff_Exc_Aux_Staff_FTE&quot; ## [31] &quot;Tot_Aux_Staff_FTE&quot; ## [32] &quot;TA_Teacher_Ratio&quot; ## [33] &quot;Pupil_Teacher_Ratio&quot; ## [34] &quot;Perc_Male_Teachers&quot; ## [35] &quot;Perc_Minority_Ethnic_Teachers&quot; ## [36] &quot;Perc_Over_Age_50_Teachers&quot; ## [37] &quot;Perc_QTS_Teachers&quot; ## [38] &quot;Perc_of_Unqual_Teachers_who_Unqual_on_QTS_Route&quot; ## [39] &quot;Perc_Male_TAs&quot; ## [40] &quot;Perc_Minority_Ethnic_TAs&quot; ## [41] &quot;Perc_HLTA_TAs&quot; ## [42] &quot;Perc_Male_Non_Classroom_Support_Staff&quot; ## [43] &quot;Perc_Minority_Ethnic_Non_Classroom_Support_Staff&quot; ## [44] &quot;Perc_Male_Aux_Staff&quot; ## [45] &quot;Perc_Minority_Ethnic_Aux_Staff&quot; ## [46] &quot;Regional_Pay_Spine&quot; ## [47] &quot;Mean_Gross_Salary_All_Teachers_Sterling&quot; ## [48] &quot;Perc_Main_Pay_Range_Classroom_Teachers&quot; ## [49] &quot;Perc_Upper_Pay_Range_Leading_Practioners_Pay_Range_Classroom_Teachers&quot; ## [50] &quot;Perc_Receive_Allowance_Qual_Classroom_Teachers&quot; ## [51] &quot;Perc_Leadership_Pay_Range_Teachers&quot; ## [52] &quot;Perc_At_Least_One_Sickness_Absence_Teachers&quot; ## [53] &quot;Tot_Days_Sickness_Absence&quot; ## [54] &quot;Mean_Days_Lost_Teacher_Sickness_Absence_Of_Those_Taking_Sickness_Absence&quot; ## [55] &quot;Mean_Days_Lost_Teacher_Sickness_Absence_All_Teachers&quot; ## [56] &quot;FT_Vacant_Posts&quot; ## [57] &quot;Perc_FT_Posts_Vacant&quot; ## [58] &quot;FT_Temp_Filled_Posts&quot; ## [59] &quot;Perc_FT_Temp_Filled_Posts&quot; Tip: Click on the name of a dataframe to open it in a new window. Click on the arrow to the left of it to see the structure of it, or type str(DATAFRAME_NAME) s We can also change column names using the above function: #Identify the column number using colnames(swfc_16) and then specify the string to change it to colnames(swfc_16)[11] &lt;- &quot;Region&quot; #...and change it back again colnames(swfc_16)[11] &lt;- &quot;Government_Office_Region_Name&quot; 5.3 Selecting certain columns/removing columns Selecting certain columns is really helpful for creating subset dataframes. Below we select the school’s LA Establishment Code, its unique identifier, and all the columns to do to do with teacher absences: teacher_absences &lt;- swfc_16[,c(2,53:55)] Let’s break this down: teacher_absences is the name of the new dataframe we’re going to create We’ve seen the get sign before swfc_16 is the dataframe we’re going to select columns from [] is for selecting a certain element from an object c() stipulates a character string, in this instance a load of numbers x:y means all numbers between and including x and y The comma and nothing before it signifies that all rows must be included - the format is dataframe[row conditions, column conditions] Whilst we can use this method to remove columns, we can also remove individual columns using a simpler method. Say for instance we wanted to remove the 2016 LA Establishment Code, the third column: swfc_16 &lt;- swfc_16[,-3] 5.4 Conditional Selections We can select subsets of dataframes based on certain conditions. There are a number of ways to do it, but this method uses functions in the basic R set of functions, known as ‘base R’: #Conditionally select primary schools swfc_16_pri &lt;- swfc_16[swfc_16$School_Phase == &quot;Primary&quot;,] Let’s break this down: swfc_16_pri is the name of the new dataframe we’re going to create We’ve seen the get sign before swfc_16 is the dataframe we’re going to conditionally select rows from [] is for selecting a certain element from an object $ is for extracting an element by name, in this instance the School_Phase column ==“Primary” signifies that rows must equal Primary The comma and then nothing after it signifies that all columns must be included - the format is dataframe[row conditions, column conditions] Activity A5.1: Use conditional selections to create a new dataframe which contains all schools whose school type is an academy. Open the dataframe to see what an academy is actually called in School_Type. Tip: After typing the dollar sign when looking for dataframe column names, pause, and a dropdown list will appear. We can also use selections on numerical variables too: swfc_16_male &lt;- swfc_16[swfc_16$Perc_Male_Teachers &gt; 50,] However, we’re not limited to just one condition: #Conditionally select schools where Pupil:Teacher Ratios are below 20 and above or equal to 10 swfc_16_ptr &lt;- swfc_16[(swfc_16$Pupil_Teacher_Ratio &lt; 20 &amp; swfc_16$Pupil_Teacher_Ratio &gt;=10),] #Conditionally select schools where Pupil:Teacher Ratios are below 10 or their LA is in Camden swfc_16_ptr_camden &lt;- swfc_16[(swfc_16$Pupil_Teacher_Ratio &lt; 10 | swfc_16$LA_Name == &quot;Camden&quot;),] Activity A5.2: Select all schools whose StatutoryLowAge is higher than 5 and have no full time posts vacant (the fourth from last column). 5.5 Altering data in dataframes Editing dataframes is a key skill. We can edit the data within columns, or create new ones. Here we edit the Religious_Character to be TRUE or FALSE. The Religious_Character column is a column of factors - strings limited to a certain number of entries. We will first turn it into a column which can contain any string, called a character column. Tip: If a column is a factor, you can see what the different entries are through levels(dataframe$column). #Turn Religious.Character to binary swfc_16$Religious_Character &lt;- as.character(swfc_16$Religious_Character) swfc_16$Religious_Character[swfc_16$Religious_Character == &#39;Does not apply&#39; | swfc_16$Religious_Character == &#39;None&#39; | swfc_16$Religious_Character == &quot;&quot;] &lt;- FALSE swfc_16$Religious_Character[swfc_16$Religious_Character != FALSE] &lt;- TRUE This uses boolean logic (TRUE or FALSE). It also uses != which means does not equal. We can calculate a new column too. In this instance we’ll work out the percentage of teaching staff that are vacancies. #Calculate percentage of posts which are vacancies swfc_16$perc_vacancies &lt;- swfc_16$FT_Vacant_Posts/swfc_16$Tot_Teachers_HC Activity A5.3: Turn all schools which arent an LA maintained school or a special school into ‘Not LA maintained’. 5.6 Writing data Activity A5.4: The function for writing is write.csv(). Use the help function (?write.csv) to work out what the arguments are for this function "],
["tidy-data-manipulation.html", "Chapter 6 Tidy data manipulation 6.1 Packages 6.2 Setup 6.3 Piping notation with dplyr 6.4 Selecting variables 6.5 Renaming variables 6.6 Distinct combinations 6.7 Making new variables / changing data types 6.8 Arranging data 6.9 Filtering data 6.10 Making new variables 6.11 Summary statistics", " Chapter 6 Tidy data manipulation 6.1 Packages One of the great things about R (and lots of other open source programming languages) is that you can add in extra functionality really easy. These extra functions come in the form of packages. 6.2 Setup To get a package, we first need to install it. This can be done in the console, as once installed, we don’t need to reinstall every time we start a new session of R. We are going to install a package called dplyr, a package to manipulate data. install.packages(&quot;dplyr&quot;) A lot of funny stuff will come up in your Console, ignore it, it’s all normal (or should be!). Once we’ve installed it, we have to load the package. This we do have to do every time we start a new session of R. #Load required libraries library(dplyr) 6.2.1 What we’ll learn with dplyr dplyr is a fantastic R package developed to help us manipulate data easily. With dplyr we can… Select columns using dplyr::select() Rename columns using and dplyr::rename() Select distinct combinations of variables using dplyr::distinct() Arrange data from high to low using dplyr::arrange() and dplyr::top_n() Filter data using dplyr::filter() Create new variable, recode variables and change column classes using dplr::mutate() Create summary statistics using a combination of dplyr::group_by() and dplyr::summarise() 6.3 Piping notation with dplyr When we do a piece of data manipulation, we need to then put what we’ve done into a new object. name_of_output_dataframe &lt;- input_dataframe %&gt;% dplyr::function(variable_name_1, variable_name2, ...) Example: selected_data_example &lt;- swfc_headcount %&gt;% dplyr::select(la_name, la_number) This will give us an object in our environment (place where our data lives in RStudio) called selected_data_example which will contain the variables la_name and la_number from the swfc_headcount data. 6.4 Selecting variables In the above example we’ve seen how we can select two variables such as la_name and la_number. selected_data_1 &lt;- swfc_headcount %&gt;% dplyr::select(la_name, la_number) If we have an object and we want all the columns bar one, we can use a minus sign. e.g. to get all the columns in the swfc_headcount data bar the la_name variable, we can use: selected_data_2 &lt;- swfc_headcount %&gt;% dplyr::select(-la_name) Exercise Now can you use the same logic to select the columns region and la_name? Output this to an object called exercise_1. Below is a starting guide to help you get going. exercise_1 &lt;- swfc_headcount %&gt;% dplyr::select() Use the same logic to select the columns teacher_count and school_name? Output this to an object called exercise_2. exercise_2 &lt;- swfc_headcount %&gt;% dplyr::select() Can you select all the variables in the swfc_headcount data apart from the school_name variable? Output this to an object called exercise_3. exercise_3 &lt;- swfc_headcount %&gt;% dplyr::select() 6.5 Renaming variables To rename a variable, we use dplyr::rename() and use the structure of saying the new name we’d like for our variable and then setting it equal to the variable as it’s named. E.g: renamed_data_example &lt;- data %&gt;% dplyr::rename(name_we_want = current_variable_name) If I wanted to rename the la_number variable to be called la_num, I’d run: renamed_data_1 &lt;- swfc_headcount %&gt;% dplyr::rename(la_num = la_number) Each time, this returns all of the variables in the data with the one we’ve renamed changed! I can rename multiple variables by using a comma such as; renamed_data_2 &lt;- swfc_headcount %&gt;% dplyr::rename(la_num = la_number,school_name_at_2018 = school_name) We can rename variables to have name’s we’d like to have presentationally with spacing in, but programming languages tend to not like this very much, so if you are to do this, please do this at the end of your analysis! Note: The use of backticks `. renamed_data_3 &lt;- swfc_headcount %&gt;% dplyr::rename(`Local Authority Number` = la_number) ` Exercise Rename the region variable from the swfc_headcount dataframe to be called govt_office_region. exercise_4 &lt;- swfc_headcount %&gt;% dplyr::rename() 6.6 Distinct combinations Sometimes we may just want to see which things are in our data, such as which schools or which regions. This can be a challenge when we have multiple rows for each observation. We can use the dplyr::distinct() function to do just this. If I wanted to see the distinct regions in the data I could run: distinct_data_1 &lt;- swfc_headcount %&gt;% dplyr::distinct(region) If I wanted to see a distinct combination of multiple varibles, for example to make a lookup table of all the local authority names and regions, I could run: distinct_data_2 &lt;- swfc_headcount %&gt;% dplyr::distinct(region, la_name) Exercise Create a lookup table of local authority names and numbers using la_name and la_number. We’ve got you started below: exercise_5 &lt;- swfc_headcount %&gt;% dplyr::distinct() 6.7 Making new variables / changing data types If I wanted to make a dummy variable to identify which schools have more than 50 teachers, I could do the following: added_variable_example_1 &lt;- swfc_headcount %&gt;% dplyr::mutate(more_than_100_teachers = ifelse(as.numeric(as.character(teacher_count)) &gt; 50, 1, 0)) Tip: Note: In the above example we made sure to treat the teacher_count variable as a numeric value, why is this? Programming languages are very good at spotting trends in data and basically defining data in a way it sees fit. In this example, out swfc_headount data has a column of teacher_count. To me and you, we’d think of this as a numeric value anyway. But, in the data, we have many DNS (Did not submit) values which R understands to be characters. So, as the column for teacher_count contains both numeric and character values, it automatically will read them in a way that is logical. Numeric values can be read as character strings, e.g. 1,2, etc. But “School” cannot possibly be numeric, so the column is read as a character. So, if we look at the structure of the teacher_count variable, using str(swfc_headcount$teacher_count)` # we&#39;ll see that the column is a set of factors # chr We can make a new variable, which reads teacher_count as numeric, which will turn the DNS (Did not sumbit) values into NA’s, so we can perform mathematical operations on the column. numeric_column_example &lt;- swfc_headcount %&gt;% dplyr::mutate(teacher_count_numeric = as.numeric(as.character(teacher_count))) Now, if we wanted to, we can perform maths on that dataframe more easily e.g. numeric_column_example_output &lt;- numeric_column_example %&gt;% dplyr::mutate(more_than_100_teachers = ifelse(teacher_count_numeric) &gt; 50, 1, 0)) 6.8 Arranging data We may be interested to see our data and look at the school’s with the biggest workforce. To do that we need to arrange our data. arranged_data_example &lt;- swfc_headcount %&gt;% dplyr::arrange(as.numeric(as.character(workforce_count))) Exercise Can you now look at which school has the most teachers? Use the teacher_count variable. exercise_6 &lt;- swfc_headcount %&gt;% dplyr::arrange(as.numeric(as.character())) 6.9 Filtering data We may want to just have the data for a particular region or local authority. Sometimes we may have multiple conditions needed when we’re looking for particular data. The dplyr::filter() function allows us to get that data. If I wanted to just get the data for my own local authority, I can filter the data to find just that, e.g. filtered_data_example_1 &lt;- swfc_headcount %&gt;% dplyr::filter(la_name == &quot;Wigan&quot;) If I wanted to get all the data for all local authorities other than Wigan, I could use filtered_data_example_2 &lt;- swfc_headcount %&gt;% dplyr::filter(la_name != &quot;Wigan&quot;) If I wanted to get all the data for two local authorities I could use filtered_data_example_3 &lt;- swfc_headcount %&gt;% dplyr::filter(la_name %in% c(&quot;Wigan&quot;, &quot;Darlington&quot;)) If I wanted to filter data on multiple conditions, e.g. on la_name and school_type, I could use filtered_data_example_4 &lt;- swfc_headcount %&gt;% dplyr::filter(la_name == &quot;Wigan&quot; &amp; school_type == &quot;LA maintained schools&quot;) If I wanted to filter the data to find schools with more than 20 teachers, filtered_data_example_5 &lt;- swfc_headcount %&gt;% dplyr::filter(as.numeric(teacher_count) &gt; 20) Exercise Can you find the data for teacher headcount in Westminister? Can you find how many teachers work at “Beckford Primary School”? 6.10 Making new variables If I wanted to make a dummy variable to identify which schools have more than 50 teachers, I could do the following: added_variable_example_1 &lt;- swfc_headcount %&gt;% dplyr::mutate(more_than_100_teachers = ifelse(as.numeric(as.character(teacher_count)) &gt; 50, 1, 0)) 6.11 Summary statistics We can create summary statistics using dplyr, which groups data by certain characteristics and then performing certain calculations - counts of each group or averages for each group - a really popular feature in Excel; can be replicated using dplyr. Counting the number of each type of school: #Calculate the number of schools by school type school_type_count &lt;- swfc_headcount %&gt;% dplyr::group_by(school_type) %&gt;% dplyr::summarise(count_schools = n()) %&gt;% dplyr::ungroup() Exercise Now use the same logic to calculate the number of schools per la_name! "],
["graphs.html", "Chapter 7 Graphs 7.1 ggplot2 7.2 Scatter plots 7.3 Bar charts 7.4 Line graphs 7.5 Displaying a third variable 7.6 Styles", " Chapter 7 Graphs 7.1 ggplot2 Another package in the tidyverse is ggplot2, used for plotting anything from graphs to maps. R has a function built into it to plot graph, unsurprisingly called plot(). However, it’s limited compared to ggplot2, which is part of the tidyverse package. Activity A7.1: Install either the ggplot2 package or the tidyverse package of packages, of which ggplot2 is one. Remember to load it up using library()! The main function in ggplot2 is ggplot, which stands for the ‘grammar of graphics’. The ‘grammar of graphics’ relates to the three elements that makes up a graphical visualisation: A dataset from which the visualisation is built Visual marks that represent the data A coordinate system - a grid on which the data is plotted In this section we’ll look at how to plot three different types of graph: Scatter plots Bar charts Line graphs We’ll also look at how to show how data of different groups can be displayed and how to alter the style of graphs. First, let’s look at the basic functions: ggplot(dataset,aes(x,y)) + geom_*() + coords_*() + styles() + styles() Let’s break this down: The first argument of the main function, ggplot, is the dataset from which the data will come from (the first of our graphical elements) The second argument, the aesthetics, in the ggplot function are the specific columns within the dataset which make up the x and y axis (also part of the first of the graphical elements) The geom_* functions, where the asterisk details the type of visualisation, is used to detail how the visual marks are displayed (the second of the elements) The coords_* functions are optional in defining the coordinate system, but if no functions are included, a standard x-y grid will be produced (the third, and least commonly used of the elements) Further multiple and optional styles can be added on Each of these are joined together with plus signs. 7.2 Scatter plots A scatter plot is a plot of points where each point is defined by a dataset’s entry’s for two variables, creating x and y axes. Here we’ll create a scatter plot (or geom_point() as it is known in ggplot) to compare the total workforce in a school and the total teaching workforce. ggplot(swfc_16,aes(Tot_Workforce_HC,Tot_Teachers_HC)) + geom_point() Activity A7.2: Explain the arguments in this graph. 7.3 Bar charts We can use bar charts to do simple counts of the number of observations belonging to each level. In the example below we use the geom_bar() function to count the number of schools of each school type: ggplot(swfc_16,aes(School_Type)) + geom_bar() Activity A7.3: What’s different about the aes() function and why? However, as well as counts we can use bar charts to display the values within the column of a dataframe. Here we calculate the average percentage of teachers with qualified teacher status for each school type. ggplot(swfc_16 %&gt;% group_by(School_Type) %&gt;% summarise(ave_perc_qts = mean(Perc_QTS_Teachers,na.rm=TRUE)), aes(School_Type,ave_perc_qts)) + geom_bar(stat=&quot;identity&quot;) Let’s break down the arguments: The first argument within ggplot() is a dplyr script to create a dataframe which contains each school type and its average percentage of qualified teachers. This negates the need to, every time, create a named dataframe. Activity A7.4: Highlight the first argument and run it. The aes() function contains two arguments this time - the x-axis and the y-axis. We need to define a y-axis because we’re going to be using values from a column, not just counts. The geom_bar() function contains an argument, stat=‘identity’, which informs the plot that it’s to use the values from a column (in this instance the ave column created in the first argument of ggplot()). 7.4 Line graphs Activity A7.5: Adjust the code above for the bar graph to produce a line graph: Replace geom_bar(stat=“identity”) with geom_line() Change the columns used to see how the TA:Teacher ratio (TA_Teacher_Ratio) varies with the total number of teachers in a school (Tot_Teachers_HC). A word of warning with line graphs though: you can use bar charts and line graphs to display changes between discrete numerical data (e.g. 1,2,3,4,5), but you should not use a line graph to display changes between categorical data (e.g. primary schools, secondary schools, special schools). This is because a line graph implies some sort of continuous variation, so each mark has a ‘distance’ from the previous (e.g. the distance between 2 and 1 is 1), but there’s no ‘distance’ between primary school and secondary school. ggplot(swfc_16 %&gt;% group_by(Tot_Teachers_HC,School_Type) %&gt;% summarise(ave_ta_teacher_ratio = mean(TA_Teacher_Ratio,na.rm=TRUE)), aes(Tot_Teachers_HC,ave_ta_teacher_ratio)) + geom_line() 7.5 Displaying a third variable We can use ggplot to plot three variables, not just two on the x and y axes. This allows the viewer to get a more detailed breakdown of the data, without having to produce multiple graphs. There are three different arguments which can be added to the aesthetic function (as they’re going to change how the graph looks), depending on what type of graph is being produced: fill= is used for bar graphs - this splits up each bar with different colours related to the proportion of each category making up that bar col= is used for line graphs - this creates lines of different colours for each different category to show how it varies size= is used for scatter plot - the size of each point relates to the value in the column In all of these arguments, after the equals sign comes the variable name that we want to plot. Here’s an bar chart example which uses fill which shows the proportions of each type of school which make up each region. Activity A7.6: Use col to adapt the line graph above to show how different each different school type’s TA:Teacher ratio varies with size of school. Finally, we’re going to use size to show a third variable on a scatterplot. Activity A7.7: Use the group_by and summarise functions in dplyr to create a dataframe which has four columns: Government Office Regions The average pay (Mean_Gross_Salary_All_Teachers_Sterling) for each of those regions The average percentage of teachers receiving allowances (Perc_Receive_Allowance_Qual_Classroom_Teachers) in each region The number of schools in each region (use n()) Your code in the summarise function will look something like: summarise(var1_name = mean(variable1,na.rm=FALSE), var2_name = mean(variable2,na.rm=FALSE), var3_name = n()) Activity A7.8: Pop your dataframe code from the activity above into a ggplot function, and create a scatter plot with the col argument as the region and the size argument as the number of schools in that region. It may seem like it should be fill not col for colouring points, but remember that a point shouldn’t really have a size - it’s an exact location, so there’s nothing to fill! 7.6 Styles So, we’ve produced a number of graphs now, but they’re not the best formatted in places… Fortunately, one of ggplot’s major selling points is that it’s really versatile with the formatting that can be done. Here are a few handy functions, all of which are added with a plus sign after you’ve detailed what plot you want: coord_flip() flips the coordinates, so the x axis is on the y axis and vice versa. This is really useful for bar graphs, to prevent labels overlapping ggtitle() allows you to specify a chart title - the argument within this function is enclosed in quotes and details what title is required xlab/ylab specify the x and y axis labels respectively and again the argument, which is the label, is enclosed in quotes theme_minimal() removes the grey background, which immediately makes it look nicer! xlim/ylim specifies the limits for continuous axes on the x and y axes respectively. They take two arguments - the lower limit and the upper limit, separated by a comma. Activity A7.9: Apply all of these functions to the graphs you’ve previously produced. "],
["statistical-operations.html", "Chapter 8 Statistical Operations 8.1 Maximum, Minimum, and Range 8.2 Averages 8.3 Correlations 8.4 Significance Testing", " Chapter 8 Statistical Operations Easily drilling down into data is one of R’s most powerful functions. As we would with Excel, we can use a number of functions to gain a better understanding of the data. 8.1 Maximum, Minimum, and Range One of the key checks to do on a dataset when loading data in is what extreme values are in each variable: The minimum The maximum The range Tip: Put closing delimiters* on a new line - it’s easier to see which opening delimiter it corresponds to. *(), {}, [] Now, we can calculate the minimum and maximum for any column we require: min(swfc_16$Pupil_Teacher_Ratio) max(swfc_16$Pupil_Teacher_Ratio) Activity A8.1: It’s coming up with NA. What’s the argument in min or max that we need to add in to return a result? We could also write this using the pipe: swfc_16 %&gt;% select(Pupil_Teacher_Ratio ) %&gt;% min(ARGUMENT_IN_HERE ) swfc_16 %&gt;% select(Pupil_Teacher_Ratio ) %&gt;% max(ARGUMENT_IN_HERE ) These two functions are really useful for identifying extreme values and outliers - potentially values which are incorrect or shouldn’t be there. We can use another function, similar to min and max, called range. Activity A8.2: Pick a variable and calculate the range. Think about the arguments you need to use. Tip: Statistical functions nearly always need to have NA values removed from the object they’re operating on. 8.2 Averages There are two averages we can calculate: Mean: This is the ‘average’ that we’re used to - add the values up and divide them by the number of values Median: Line them all up in order, count to the middle value (if its an even number of values, go for halfway between the two middle values) Let’s apply each of these to a subset of the main dataset. Mean: #The mean of the total school workforce for primary schools swfc_16 %&gt;% filter(School_Phase == &#39;Primary&#39;) %&gt;% group_by(School_Phase) %&gt;% summarise(Ave = mean(Tot_Workforce_HC,na.rm=TRUE)) Median: #The median of the total school workforce for primary schools swfc_16 %&gt;% filter(School_Type == &#39;Academies&#39;) %&gt;% group_by(School_Type) %&gt;% summarise(Ave = median(Tot_Workforce_HC,na.rm=TRUE)) 8.3 Correlations We can calculate correlations between 2 or more values. Let’s just start with two variables: #Base R cor(swfc_16[,c(15,16)],use=&quot;complete.obs&quot;) ## StatutoryHighAge Tot_Workforce_HC ## StatutoryHighAge 1.0000000 0.6099884 ## Tot_Workforce_HC 0.6099884 1.0000000 #Pipes swfc_16 %&gt;% select(StatutoryLowAge,StatutoryHighAge)%&gt;% cor(use=&quot;complete.obs&quot;) ## StatutoryLowAge StatutoryHighAge ## StatutoryLowAge 1.0000000 0.7454194 ## StatutoryHighAge 0.7454194 1.0000000 #use=&quot;complete.obs&quot; means only use the observations where the data is present in both columns Activity A8.3: Create an object (a correlation matrix) which has the correlations for all the columns between StatutoryLowAge and Tot_TAs_HC. Assign it to an object name. 8.4 Significance Testing This isn’t a stats course, but significance testing is a really handy technique for analysing data - the first step in learning statistical techniques in a data analyst’s/scientist’s toolkit, and can be relatively easily executed in R. In practical terms, significance testing is quantifying how confident we are two groups are different to one another. Suppose we wanted to test whether primary schools had significantly different total workforces to the school population overall. t.test(swfc_16 %&gt;% filter(School_Phase == &quot;Primary&quot; ) %&gt;% select(Tot_Workforce_HC), mu = mean(swfc_16$Tot_Workforce_HC,na.rm=TRUE), alternative = &quot;less&quot;) t.test(swfc_16[swfc_16$School_Phase == &quot;Primary&quot;,17], mu = mean(swfc_16$Tot_Workforce_HC,na.rm=TRUE), alternative = &quot;less&quot;) Let’s break the input down: t.test(): The technique to test for a significant difference is called a T-test - in this instance we’re carrying out a ‘one-tail’ T-test, which in this instance means checking whether the average of a sample significantly differs from the average of the entire population. Argument 1: The first argument is the sample that we want to the population against. In this instance it’s primary schools. Argument 2: mu is the average of the population. Argument 3: We want to test whether the sample average is ‘less’ than population average. This could also be ‘greater’. ## ## One Sample t-test ## ## data: swfc_16 %&gt;% filter(School_Phase == &quot;Primary&quot;) %&gt;% select(Tot_Workforce_HC) ## t = -67.484, df = 16683, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean is less than 59.69092 ## 95 percent confidence interval: ## -Inf 46.84931 ## sample estimates: ## mean of x ## 46.52847 Now let’s break the output down (in reverse order from how it’s displayed): Mean of x: This is the average of the sample: 46.5287. Confidence intervals: 95% of the time (i.e. 19 out of 20 times), the average of any random sample of the overall population will be outside the confidence intervals. Here, because we’re only checking whether the sample’s average than the population’s average, we only need a confidence interval above the mean: 46.84931. p-value: To be confident that there is a significant difference, this number needs to be less than 0.05 (i.e. only 1 time out of 20 will a random sample of primary schools we take from the population be smaller than the upper confidence interval. Simple?!? Activity A8.4: Test whether schools in Camden LA District have a significantly higher percentage of vacant posts (column name is FT_Vacant_Posts) than England as a whole, using a t-test. Repeat for lower. As well as comparing a sample to a population we can compare two samples. What we are doing is testing whether the difference of the averages of two samples is significantly different to zero, i.e. there is a difference. In this example we’re going to test whether primary schools have a significantly different percentage of teachers who are male to schools that have a phase of ‘All Through’. t.test(Perc_Male_Teachers ~ School_Phase, data = (swfc_16 %&gt;% filter(School_Phase == &quot;Primary&quot; | School_Phase == &quot;All Through&quot;) %&gt;% select(School_Phase, Perc_Male_Teachers))) Let’s break the input down: t-test: As above Argument 1: This contains the variable that we’re going to compare the groups on (percentage of teachers that are male), and the characteristic that defines the groups (phase). But there’s more than one phase of school I hear you say… Argument 2: Fear not. In the second argument we use some dplyr to do some filtering. We only select schools that are primary or all through, and we only select the school phase and percentage of teachers that are male columns. ## ## Welch Two Sample t-test ## ## data: Perc_Male_Teachers by School_Phase ## t = 22.812, df = 151.8, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 15.56238 18.51366 ## sample estimates: ## mean in group All Through mean in group Primary ## 31.81972 14.78170 Now let’s break the output down: Welch: Dunno who Welch is, but their t-test is the standard one for testing two samples Group means (at the bottom): These are the means of the two samples that we’re comparing Confidence intervals: 95% of the time (i.e. 19 out of 20 times), the average of any random samples taken from each of the groups (primary and all through) will have a difference in their averages of between 15.56238 and 18.51366. Both of those numbers are above 0, so this is looking good… p-value: Again, to be confident that there is a significant difference, this number needs to be less than 0.05 (i.e. only 1 time out of 20 will random samples from primary schools and all through schools be outside the confidence intervals above) Activity A8.5: Test whether schools in Camden and Northumberland LA Districts have significantly different percentage of vacant posts (column name is FT_Vacant_Posts) than England as a whole, using a two sample t-test. Tip: For more info on t-tests, go to this page on dummies.com. Also, try out this page for an interactive two sample t-test calculator if you want a bit more practice. "],
["iteration.html", "Chapter 9 Iteration 9.1 if 9.2 for loops 9.3 while loops 9.4 How could we use loops?", " Chapter 9 Iteration One of the most powerful uses of any programming language is its ability to do a task over and over again really quickly - this is known as iteration. Tip: Iteration isn’t actually the most efficient way of writing code, because it processes each item it iterates over one at a time. A more efficient way to process code is to ‘vectorise’ your code - this means writing code to process all the items at once. We’ve already done this when we’ve been manipulating columns of data in one go - we could have written an iterative function to go over each item in the column and manipulate it. That said, iteration is a really important process to learn, because it helps you understand the sort of ‘decisions’ a computer will make in the background when executing code. There are three types of iterative function that we’ll look at: An if statement - a function that will do one thing if a condition is met or is true, and another thing is that condition is not met or is false A for loop - a function that will repeat a task for every item in a list or a certain number of iterations A while - function that will repeat a task for as long as a condition is met or is true All of the functions here take a similar format: function(condition to be met){ action to be carried out if condition is met #Note how it has to be indented } 9.1 if As mentioned above, if statements are for carrying out an action if a condition is met or is true. For example, say we were trying to create a recreate whether a fictitious teacher was male or female, if we knew the probability that a teacher was male, we could build an if statement that said: Generate a random number between 0 and 1 If that number is less than or equal to the probability that a teacher is male, then say our fictitious teacher is male If that number is more than the probability that a teacher is male, then say our fictitious teacher is female First, let’s work out the probability that a teacher is male. This is the average percentage of male teachers divided by 100, to make it a probability. prob_male &lt;- swfc_16$Perc_Male_Teachers %&gt;% mean(na.rm = TRUE)/100 Now, let’s generate our random number using the runif function. rand_num &lt;- runif(1) Now let’s write our if statement. if(rand_num&lt;=prob_male){ print(&quot;M&quot;) } So now if our random number is less than or equal to the probability a teacher is male that it will print ‘M’. However, if it’s over the probability, nothing will happen. To ensure something does happen we can use the else function, which will execute an action if the condition is not met. if(rand_num&lt;=prob_male){ print(&quot;M&quot;) }else{ print(&quot;F&quot;) } Activity A9.1: How could we streamline the code we’ve just written by replacing object names? 9.2 for loops A for loop - a function that will repeat a task for every item in a list or a certain number of iterations. Say we wanted to create a fictitious school which contained 10 teachers, we could write a for loop that for 10 iterations repeated the if statement above. for(i in 1:10){ if(runif(1)&lt;=prob_male){ print(&quot;M&quot;) }else{ print(&quot;F&quot;) } } Let’s break this down the for loop argument: The i is the name of an object that will take a different value at each iteration (1st iteration, 2nd iteration, etc) of the for loop in 1:10 details the different values i will take: 1st iteration - i=1, 2nd iteration i=2, etc. The action to execute at each stage between the curly braces, which in this instance is the if statement from above Activity A9.2: Adapt the for loop above to create an empty object and at each iteration add the result from the if statement to that object. The functions you’ll need are below: #For creating an empty object character(0) #For joining values to an existing object c(object,value) 9.3 while loops A while loop while perform an action for as long as the condition specified in the function’s argument is true. Activity A9.3: Write the function below out and run it. As 2 while always be greater than 1 what is going to happen? while(1&lt;2){ print(&quot;This is going to take a while...&quot;) } Tip: Stop a bit of code from running by clicking on the red stop sign in the top right hand corner of the console. Typically, a while loop will look like this: object &lt;- starting_value while(condition_of_object){ action object &lt;- change_value_of_object } #For example i &lt;- 1 while(i&lt;5){ print(paste0(&quot;This is a while loop, we&#39;re at iteration &quot;, as.character(i))) i&lt;-i+1 } Tip: paste0() is a really useful function that glues strings together. It’s different to c() in that it turns multiple strings into one string, whereas c() turns them into a vector of multiple strings. Activity A9.4: Add 3 while loops after your for loop above so that while i equals 1 you add ‘Headteacher’ to an object, while i is less than 5 you add ‘Senior Leader’ to the same object, and while i is greater or equal to 5 you add ‘Classroom Teacher’ to the same object. Once this has run put the gender object and the object denoting the seniority of the teacher into a dataframe called my_school with the column headings as gender and grade. 9.4 How could we use loops? Loops are really useful for building models of systems, to use probabilities (as we did with the gender probabilities) to predict how entities (called agents in modelling) will behave in a system. These models can be run multiple times and the outputs recorded each time to give a distribution of how likely each outcome is to occur based on different behaviours along the modelled actions. "],
["functions.html", "Chapter 10 Functions 10.1 Writing functions 10.2 Applying functions repetitively", " Chapter 10 Functions We’ve used a lot of functions up until now, and understand the format of a function, with the function name and then the arguments inside the brackets. It essentially takes the form: verb(noun,adverbs) Where the verb is the thing we want to do, the noun (as the first argument) is the object we want to do it to, and the adverbs (as the subsequent arguments) are the descriptions of how we want to do it. However, there’s going to come a time when we want to do the same thing again and again, to a lot of different objectives, and there won’t be a specific function to write it. Don’t worry though, you can do write your own functions. 10.1 Writing functions A function is comprised of three parts: function_name &lt;- function(function_argument1,function_argument2,etc){ function_actions } So, a function that divides an object by 100 looks like this: my_func &lt;- function(x){ x/100 } Here x is the noun that we’re doing something to. To create the function, simply run that code. Activity A10.1: Use mutate and multiply Perc_PT_Teaching_Staff_ by 100 in a new column called perc_pt_test. Activity A10.2: Remember the code from the iteration section on deciding whether a fictional teacher was male or female? if(rand_num&lt;=prob_male){ print(&quot;M&quot;) }else{ print(&quot;F&quot;) } Turn that into a function, with the random number as the ‘noun’. Once you’ve written it, run it with a few different numbers in the argument. It’s also really handy for producing graphs when we want to filter them by different categories. Say we wanted to look at a histogram of the total school workforce, to get an idea of the distribution of school sizes in a particular region, we could make a graph like this (with Inner London as an example): ggplot(swfc_16 %&gt;% filter(Government_Office_Region_Name == &#39;Inner London&#39;), aes(Tot_Workforce_HC)) + geom_histogram() + ggtitle(&#39;Distribution of school size in Inner London&#39;) However, ‘Inner London’ could be any one of the 9 other regions in England - we could vary this value. By varying it we are making it a parameter - a value in our input code that can change. We can produce exactly the same output by replacing the string ‘Inner London’ with an object name, and creating that object before we create the graph (remember the paste0 function that we used in the iteration section). region_name &lt;- &#39;Inner London&#39; ggplot(swfc_16 %&gt;% filter(Government_Office_Region_Name == region_name), aes(Tot_Workforce_HC)) + geom_histogram() + ggtitle(paste0(&#39;Distribution of school size in &#39;,region_name)) Activity A10.3: Using the code above, create a function which you could put in any region name, and as long as that region is correct, the function produces a graph. 10.2 Applying functions repetitively Writing a lot of code get boring and laborious. Writing a lot of code that does the same thing again and again gets really boring and laborious. It can also lead to errors - if you copy and paste code enough times eventually you’ll make a mistake, which could lead to incorrect analysis. However, as already mentioned, if you’re doing something again and again, then building a function is really useful. Suppose we do want to create graphs of all 10 regions, using the code above? We have the function to produce a graph, what we need now is to work out how to repeat the graph again and again, changing the region parameter. We could use a for loop, but remember that’s not the most effective way. We want to ‘vectorise our code’. A function called lapply applies a function to a list of objects. Activity A10.3: The Government_Office_Region_Name column is a factor column - use levels() to generate a list of the different possible entries to that column The lapply function works in the following way: lapply(multiple_objects_to_apply_function_to,function(argument_name) specific_function_to_apply(argument_name)) The word function at the start of the second argument specifies that you’re about to write a function name, and essentially says ‘make each object in the list in the first argument the value of argument_name and apply the specific function to it’. You can choose any string you like for argument_name, as long as it’s the same in both places. Activity A10.3: Use lapply to print a graph showing the distribution of school sizes in the Plot pane for every single region in England. We can also use lapply to do the same thing to data in multiple columns. The difference here is that we want to turn the outputs of the lapply into an object. That object just so happens to be the same thing that goes in to the first argument in lapply. So if we wanted to turn all the columns with ‘Perc’ in the column title, that is those columns that are a percentage, from a number out of 100 to a number out of 1, by dividing by 100, we’d apply the following code: swfc_16[,grep(&quot;Perc&quot;, colnames(swfc_16))] &lt;- lapply(swfc_16[,grep(&quot;Perc&quot;, colnames(swfc_16))],function(x) my_func(x)) Let’s break this down: swfc_16[,grep(“Perc”, colnames(swfc_16))] are all the columns in swfc_16 which contain ‘Perc’. The function grep finds all the columns which contain the substring ‘Perc’. Within lapply, the first argument is the same set of columns - we’re essentially doing an update on those columns The function we’re applying is my_func, which divided the object by 100 Activity A10.3: Use lapply to turn columns 6 to 10 (swfc_16[,grep(“Perc”, c(6:10))]) into character columns, from factor columns. "],
["maps.html", "Chapter 11 Maps 11.1 Loading in geospatial data 11.2 Coordinate systems 11.3 Transforming mapping data 11.4 Point maps 11.5 Chloropleth maps", " Chapter 11 Maps Maps in R are best plotted using ggplot - which is good, because we already know how to use that! However, the new thing about maps is the sort of data we’ll be using - as well as having data about certain variables, this data has a location attached to it too. First, we need to load in the packages we need. We’ll need the following packages: tidyverse, as this contains ggplot2 for plotting and dplyr for data manipulation rgdal, a package for loading in spatial data broom, a package for converting spatial data into dataframes to be plotted in ggplot2 Activity A11.1: Install rgdal Install broom Use library() to load tidyverse, rgdal, and broom 11.1 Loading in geospatial data Geospatial data comes in three forms: Polygons (shapes) Lines Points Polygons and points are the most common (geospatial line data only really features when relating to travel infrastructure or people movements), so we’ll focus on these two. Point, polygon, and line data can come in a number of different data formats, but the msot common is a ‘shapefile’ with a .shp suffix. We can use the rgdal library to load in shapefiles. Firstly, we’re going to load the names of location of major UK cities using the readOGR function. Make sure you have the shapefiles located in a folder called shps within your data folder first. cities &lt;- &quot;data/SHPs/england_cities.shp&quot; %&gt;% readOGR() ## OGR data source with driver: ESRI Shapefile ## Source: &quot;/home/travis/build/dfe-analytical-services/r-training-course/data/SHPs/england_cities.shp&quot;, layer: &quot;england_cities&quot; ## with 48 features ## It has 2 fields Plotted, the cities look like this: …which looks vaguely like the UK! You’ll see cities is a SpatialPointsDataFrame class object. The essentially means it’s a dataframe with spatial data attached. Activity A11.2: Click the blue circle to the left of cities to open up the object. You’ll see there’s an attribute within cities called data, and another attribute called coords. Access these by typing cities@ and then whichever of the attributes you want to view. We can also use readOGR to load in polygon data. The file we’re going to use is one containing the boundaries of Local Authorities (LAs) in England, called England_LA_2016.shp. england &lt;- &quot;data/SHPs/England_LA_2016.shp&quot; %&gt;% readOGR() ## OGR data source with driver: ESRI Shapefile ## Source: &quot;/home/travis/build/dfe-analytical-services/r-training-course/data/SHPs/England_LA_2016.shp&quot;, layer: &quot;England_LA_2016&quot; ## with 152 features ## It has 8 fields This is a SpatialPolygonsDataFrame, which makes sense! However, if we plot the LAs alongside the cities, the don’t match up. ## integer(0) What we have here is all of the city points plotted down in the bottom lefthand corner (although you can only see one) over the LA map. This is because the cities data and the LA data use different ‘coordinate systems’. 11.2 Coordinate systems At their most basic level, coordinates are just numbers that represent a location, where all the points within that set follow the same form. With that in mind, we can use different sets of numbers, or systems, to represent the location of a point. There are a lot of coordinate systems that are used in mapping, but the most common that you’ll come across when mapping UK data are: WGS84 (EPSG4326): This is the standard Latitude and Longitude coordinate system to map global data, developed in 1984. It makes the assumption that the earth is a perfect sphere (it’s actually a bit elliptical - wider at the sides), and Longitude (on the x axis) goes between -180 and 180 (degrees), with 0 being the Meridian Line in Greenwich, London. Latitude (on the y axis) again goes between -180 and 180, with 0 on the Equator. OSGB36 (EPSG27700): This is a grid system, with units in metres, specific to the UK. It’s origin is about 100km west of Lands End, roughly level with the most southerly point of the mainland Britain, Lizard Point. It assumes that the British Isles are on a completely flat plane (which of course they aren’t). On the x axis are Eastings and on the y axis are Northings. The largest coordinate value is (800000,1300000). Tip: The EPSG codes are codees from the now defunct European Petroleum Survey Group, and are a common code for different coordinate systems. These are the codes that we’ll use to change the coordinate systems. For more information on codes click here. Let’s check which coordinate systems cities and england are on. #Find out the coordinate system of cities cities@proj4string ## CRS arguments: ## +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 So, cities is on WGS84 - we can see from its datum (origin) attribute. #Find out the coordinate system of england england@proj4string ## CRS arguments: ## +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 ## +y_0=-100000 +datum=OSGB36 +units=m +no_defs +ellps=airy ## +towgs84=446.448,-125.157,542.060,0.1502,0.2470,0.8421,-20.4894 So, england is on OSGB36 - again we can see from its datum attribute. Therefore, we need to translate one of the coordinate systems into the other. We’re going to convert cities into the OSGB36 coordinate system, because it’s a bit more of an intuitive system to use, using a grid in metres instead of degrees. cities &lt;- cities %&gt;% spTransform(CRS(&quot;+init=epsg:27700&quot;)) Let’s break this down: cities is our object name, and the first ingredient in our ‘recipe’ using pipes. We’re essentially updating cities. spTransform is a function for transforming spatial objects’ coordinate systems CRS stands for ‘Coordinate Reference System’ - this takes an argument which is a string containing the EPSG code of the coordinate system we want to convert to, which in this instance is EPSG27700 Activity A11.1: After you’ve run the code above, recheck which coordinate system cities is on. Now if we replot cities and england, we’ll see they line up more as we’d expect. ## integer(0) 11.3 Transforming mapping data As mentioned, we’re going to be using ggplot to plot the maps. However, ggplot takes dataframes, and currently we have spatial dataframes, so that’s not going to fly. What we need to do is convert our spatial dataframes into normal dataframes. There are two methods for this: For point data we can just convert it straight to a normal dataframe, and select the coordinates and any other required columns (e.g. labels) For polygon data we need to use a broom function called tidy, which breaks a polygon up into a series of lines, and creates a dataframe where each row is a coordinate of the start of one line and the stop of another, as well as a column detailing which group (in this instance a Local Authority) it’s part of Let’s deal with the point data first. cities_df &lt;- cities %&gt;% #Create a dataframe (df) version of cities data.frame() cities_df &lt;- cities %&gt;% #Create a dataframe (df) version of cities data.frame() %&gt;% select(city=City, easting = coords.x1, northing = coords.x2) Which creates something that looks like this: ## city easting northing ## 1 Bath 374654.4 164546.7 ## 2 Birmingham 405758.2 285421.0 ## 3 Bradford 416570.4 431915.0 ## 4 Brighton 531128.8 104856.1 ## 5 Bristol 359560.8 172496.5 ## 6 Cambridge 544754.9 257863.3 Activity A11.2: We need to do a bit of cleaning on this dataframe. Select only three columns, rename coords.x1 as easting and coords.x2 as northing. With a polygon object, we can’t just use the data.frame function, because unlike a point object, there are multiple coordinates associated with each item in the data slot. So this is where we’re going to use tidy. england_df &lt;- england %&gt;% tidy() %&gt;% as.tbl() #We need this function to explicitly specify that that output is a dataframe Which leaves us with something that looks like this: ## # A tibble: 6 x 7 ## long lat order hole piece group id ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;lgl&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; ## 1 447097. 537152. 1 FALSE 1 0.1 0 ## 2 447229. 537033. 2 FALSE 1 0.1 0 ## 3 447281. 537120. 3 FALSE 1 0.1 0 ## 4 447378. 537095. 4 FALSE 1 0.1 0 ## 5 447455. 537024. 5 FALSE 1 0.1 0 ## 6 447551. 537078. 6 FALSE 1 0.1 0 There are a few things to notice about this dataframe: The tidy function, when applied to spatial objects, automatically names the coordinate columns long and lat. In this instance long is actually easting and lat is actually northing - we’ll change the names in a minute. There are three defunct columns for our purposes: order, hole, and piece There’s no identifier for a Local Authority (name or code), which is present in the data slot of england. This has been replaced by the id column - each polygon’s points are identified by a unique number in that column. When we plot this data, ggplot2 will initially plot each of these polygons as one continuous line. This means that if one polygon does not start (indicated by the order column) at different coordinates to where the previous polygon finished, then a straight line across a polygon will appear (like the example below), connecting the two points. The group column prevents this from happening by not linking polygons in different groups. ggplot()+ geom_polygon(data=england_df, aes(long,lat), col=&quot;grey&quot;, fill=NA) + coord_equal() + theme_minimal() + theme(axis.line=element_blank(), axis.text.x=element_blank(), axis.text.y=element_blank(), axis.ticks=element_blank(), axis.title.x=element_blank(), axis.title.y=element_blank(), panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank(), legend.title=element_blank()) So, we need to create another dataframe which has all the data from england as well as an id column, to match to the dataframe that we’ve just created. england_data &lt;- england@data %&gt;% cbind(england_df %&gt;% select(id) %&gt;% unique()) #Here we&#39;re binding the unique values from the id column in england_df to the data slot from england - the order remains the same which is why we can just bind them This dataframe looks like this: ## LA15CD LA15NM LA_Code RSC_Code ## 0 E06000001 Hartlepool 805 5 ## 1 E06000002 Middlesbrough 806 5 ## 2 E06000003 Redcar and Cleveland 807 5 ## 3 E06000004 Stockton-on-Tees 808 5 ## 4 E06000005 Darlington 841 5 ## 5 E06000006 Halton 876 8 ## RSC_Name Reg_Code RGN15CD RGN15NM id ## 0 North 9 E12000001 North East 0 ## 1 North 9 E12000001 North East 1 ## 2 North 9 E12000001 North East 2 ## 3 North 9 E12000001 North East 3 ## 4 North 9 E12000001 North East 4 ## 5 Lancashire &amp; West Yorkshire 8 E12000002 North West 5 Activity A11.3: Match england_data into england_df, using id and an inner join. Keep the following columns using select: long (renaming it easting), lat (renaming it northing), LA15NM, LA15CD, and group. The data is now in a format where we can get plotting! 11.4 Point maps Point maps are useful where you want to show the location of entities with a single location, and attributes/values associated with that entity. In this example we’re going to map all schools within the Local Authority of Wiltshire, along with their phase and size. First, we want to load in the data we’re going to be using. We’re going to load in the shapefile called wiltshire_schools and transform it in one fell swoop. wiltshire_schools_df &lt;- &quot;data/shps/wiltshire_schools.shp&quot; %&gt;% readOGR() %&gt;% data.frame() %&gt;% select(easting = coords.x1, northing = coords.x2, LAEst:P_FT_T) ## OGR data source with driver: ESRI Shapefile ## Source: &quot;/home/travis/build/dfe-analytical-services/r-training-course/data/shps/wiltshire_schools.shp&quot;, layer: &quot;wiltshire_schools&quot; ## with 231 features ## It has 53 fields Tip: If you look at the dataframe, you’ll see the column names have been abbreviated - this is because shapefiles are limited to 8 characters for column names. However, we can refer to swfc_16_init to work out what the column names are. We can now finally plot some data! ggplot() + geom_point(data=wiltshire_schools_df,aes(easting,northing)) So, we’ve plotted some data, but it doesn’t look overly map like. Let’s break down what we’ve written first, and then we’ll make it look more like a map: ggplot(): The standard function, but notice here it has no arguments. This is because ggplot2 also allows you to specify your data and aesthetics from within the type of plot you’re displaying. This is really useful when you’re plotting different types of graphs from different data sources on the same coordinate system. geom_point: We’ve seen this before with scatter plots - it’s the same thing applied to spatial point data. data=wiltshire_schools_df: This is the data we’re using, the quirk here is that when specifying data within the type of plot as opposed to from within ggplot we need to explicitly specify the name of the argument, with data=. aes(easting,northing): Standard aesthetics, plotting the Easting and Northing of each plot Now let’s makr it look more like a map. The first thing we can do is make the coordinates an equal scale (currently the x-axis is more stretched than the y-axis), and get rid of the grey background, the grid lines, and then axis labels. ggplot() + geom_point(data=wiltshire_schools_df,aes(easting,northing)) + coord_equal() + theme(axis.line=element_blank(), axis.text=element_blank(), axis.ticks=element_blank(), axis.title=element_blank(), panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank()) There’s a lot to specify in the theme function, but once you’ve written it once you can copy it again and again (or even write a function to make it more concise/robust!). That’s looking more map-like! What would really help is the border of Wiltshire. To do that we need to get a subset of england_df which only contains coordinates which bound Wiltshire: wiltshire_df &lt;- england_df %&gt;% filter(LA15NM == &quot;Wiltshire&quot;) We can then add a polygon to our map: ggplot() + geom_polygon(data=wiltshire_df,aes(easting,northing),col=&quot;grey&quot;,fill=NA) + geom_point(data=wiltshire_schools_df,aes(easting,northing)) + coord_equal() + theme(axis.line=element_blank(), axis.text=element_blank(), axis.ticks=element_blank(), axis.title=element_blank(), panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank(), legend.title = element_blank()) That’s more like it! Let’s break down what we’ve got: geom_polygon: This plots a polygon data=wiltshire_df,aes(easting,northing): We’ve seen this format before col=“grey”,fill=NA: We want a grey outline and no fill colour Notice how we plot the polygon first - this is because ggplot2 builds up layers on top of each other, so we want the points on top of the polygon. The final thing we need to do is add some attributes to the points. This uses the same arguments we’ve used in plotting graphs. Activity A11.4: Use col= and size= in the aesthetics in geom_point to detail the phase of the school (column name Sch_P in wiltshire_schools_df) and the size of the school’s workforce (column name T_W_H in wiltshire_schools_df) Tip: Add in legend.title = element_blank() to get rid of the legend title and legend.key = element_rect(fill=NA) to get rid of the grey backgrounds behind the legen - both just make it look a bit more professional! 11.5 Chloropleth maps The other type of map that we’re going to look at are chloropleth maps. Chloropleth maps are maps of multiple polygons with each polygon filled in with a certain colour/hatching depending on a certain attribute/value. A chloropleth map uses similar code to a point map. We’re going to plot a map which has the average total workforce for schools in each Local Authority on it. However, the first thing we need to do is to attach data on the average school workforce for each Local Authority from swfc_16 to england_df. england_df &lt;- england_df %&gt;% inner_join(swfc_16 %&gt;% group_by(LA_Name) %&gt;% summarise(ave_tot_workforce = mean(Tot_Workforce_HC,na.rm=TRUE)),by=c(&quot;LA15NM&quot;=&quot;LA_Name&quot;)) ## Warning: Column `LA15NM`/`LA_Name` joining factors with different levels, ## coercing to character vector This gives us a dataframe that looks like this: ## # A tibble: 6 x 6 ## easting northing group LA15CD LA15NM ave_tot_workforce ## &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 447097. 537152. 0.1 E06000001 Hartlepool 67.2 ## 2 447229. 537033. 0.1 E06000001 Hartlepool 67.2 ## 3 447281. 537120. 0.1 E06000001 Hartlepool 67.2 ## 4 447378. 537095. 0.1 E06000001 Hartlepool 67.2 ## 5 447455. 537024. 0.1 E06000001 Hartlepool 67.2 ## 6 447551. 537078. 0.1 E06000001 Hartlepool 67.2 We can plot a simple chloropleth: ggplot()+ geom_polygon(data=england_df, aes(easting,northing,group=group,fill=ave_tot_workforce), col=&quot;grey&quot;) + coord_equal() + theme(axis.line=element_blank(), axis.text=element_blank(), axis.ticks=element_blank(), axis.title=element_blank(), panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank(), legend.title = element_blank()) The two key differences to a point map are: The use of the group argument, to remove lines across polygons to connect them all The use of the fill argument with the ave_tot_workforce, which fills each Local Authority polygon with a colour corresponding to its value The key thing that our chloropleth map is currently missing is some sort of reference to actual locations. However, we’ve got our city point data which we can add in, along with text labels. We have to build this up in two stages, so the first thing we’ll add in are the points: ggplot()+ geom_polygon(data=england_df, aes(easting,northing,group=group,fill=ave_tot_workforce), col=&quot;grey&quot;) + geom_point(data=cities_df, aes(easting,northing), col=&quot;red&quot;) + coord_equal() + theme(axis.line=element_blank(), axis.text=element_blank(), axis.ticks=element_blank(), axis.title=element_blank(), panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank(), legend.title = element_blank()) So we’ve plotted the location of the cities, using geom_point, which we’ve used before. To add the labels we need to use a new function however, called geom_text. ggplot()+ geom_polygon(data=england_df, aes(easting,northing,group=group,fill=ave_tot_workforce), col=&quot;grey&quot;) + geom_point(data=cities_df, aes(easting,northing), col=&quot;red&quot;) + geom_text(data=cities_df, aes(easting,northing,label=city), check_overlap = TRUE, col=&quot;red&quot;, hjust = 1.1, vjust=0.3) + coord_equal() + theme(axis.line=element_blank(), axis.text=element_blank(), axis.ticks=element_blank(), axis.title=element_blank(), panel.background=element_blank(), panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), plot.background=element_blank(), legend.title = element_blank()) Let’s break geom_text down: We’ve seen data= and the first two arguments of aes before label=city adds a text label of a certain value to the coordinates detailed in easting and northing check_overlap = TRUE checks if a each label overlaps with a previous label, and if it does, it won’t plot it. For example, ‘Bristol’ overlaps with ‘Bath’, so because Bristol comes after Bath, it isn’t plotted. col = “red” makes the text colour red hjust = 1.1 and vjust=0.3 make adjustments to the horizontal and vertical position of the label in relation to the point. This has been done so that the label doesn’t sit right on top of the point. "],
["r-markdown.html", "Chapter 12 R Markdown 12.1 Text 12.2 Code 12.3 Multiple Reports", " Chapter 12 R Markdown We now know how to do a range of data analysis, as well as producing a lot of different visualisations. Now we need to know how to compile all of that into a report, and automatically produce that report. The has numerous benefits over the traditional Excel and Word approach to writing out analysis: Faster, once the template is written More robust - errors are less likely to occur, particuarly when copying from Excel to Word Can be updated immediately if/when data changes There are two elements to R Markdown, the text (which has a number of ways of formatting it) and the code (which can be displayed and included in different ways). We’ll look at both of these, but first, we need to open an R Markdown file: Go to File Go to New File Click on R Markdown A new tab will open up in the script pane - have a look at it as it contains an example R Markdown template in the top right hand corner of the script pane click on the arrow next to Knit and click on ‘Knit to HTML’ Save the R Markdown file in the ‘2_code’ folder The code will run and the output will pop up upon completion Compare this to the input file The output file will have saved in the ‘2_code’ folder - it shouldn’t output to here, but we’ll sort that later This is how you generate an R Markdown document. When you make changes to it from now on, you won’t have to specify the name and save location every time you knit it. Tip: HTML is the preferable output - it is more versatile in designs and can include interactive elements, however if you want to you can also output to Word, and if you have additional software installed (called LaTex and pronounced ‘lay-tec’) you can output straight to PDF. 12.1 Text We can see from the template above that there are a range of ways of formatting text to render it to look good in a report. First of all, headings. Headings are generated by sequential hashes - one hash is the largest heading, and six hashes is the smallest heading. These can be used to create a series of sub-headings in documents. # Heading 1 Heading 1 ## Heading 2 Heading 2 ### Heading 3 Heading 3 #### Heading 4 Heading 4 Activity A10.3: Add some headings and change the sizes of some of the headings in the template. Run the R Markdown document and see how they output. Another useful formatting feature are lists. These can either be ‘ordered’ (1, 2, 3 or a, b, c) or ‘unordered’ (bullet points). The two examples below how to produce ordered and unordered lists, but there are three important things to remember with lists: There must be a clear line in between the end of the prose above the list and the list itself There must be a space between the character that denotes the list item and the prose There must be a clear line in between the end of the list and the prose below An unordered list: * Thing 1 * Thing 2 * Thing 3 An unordered list: Thing 1 Thing 2 Thing 3 An ordered list: 1. Thing 1 2. Thing 2 3. Thing 3 An ordered list: Thing 1 Thing 2 Thing 3 Activity A10.3: Add some headings and change the sizes of some of the headings in the template. Run the R Markdown document and see how they output. The final formatting feature to demonstrate in this chapter are creating hyperlinks. To create the hyperlink, the text to be made a link is bound in square brackets, and the address of the link comes immediately afterwards bound by brackets: A [link](http://www.yourlinkhere.com) A link Tip: There is loads more functionality in R Markdown for different formatting - just Google it! 12.2 Code However, the text edits we can make to R Markdown documents are only half of the story - the beauty of it is that you can merge text and the outputs of code. So how do we include code? Code in R Markdown is written in ‘chunks’. Chunks are written in the form below and appear in an R Markdown in a slightly grey section: ```{r} print(’hello world) ``` Let’s break that down: 3 grave accents signify the start of the code chunk {} signify the metadata that goes with the chunk - more on this in a minute Inside the curly brackets, the r signifies the programming language we’re going to be writing in We’ve then got some code - as many lines as you want with whatever outputs you want 3 grave accents close of the code chunk Here’s what it looks like in an output: print(&#39;hello world&#39;) [1] &quot;hello world&quot; Activity: Write this out and run it in your R Markdown documents. Sometimes we’ll want to include this code with outputs, sometimes only outputs, sometimes only code. We can control this using effect messages. Effect messages appear after the r within the curly brackets: ```{r, effect_message_here} With an effect message you will specify whether that effect is true or false. The list below shows the effect messages that are likely to be useful - the default for all of the message below is true. eval = FALSE: Prints the code but not the results warning = FALSE: Hides any warnings that come with the code echo = FALSE: Hides the code but prints the results include = FALSE: Hides code and doesn’t print any results (good for setup sections which load in libraries and data) message = FALSE: Removes any other messages that come with an output (this is the least common of this set) Tip: After r in a code chunk include a new for that chunk - it makes navigating easier, which can be done by clicking in the bottom lefthand corner of the script pane. You can’t have multiple sections with the same name though. Activity: Run the code below five times. The first four timed include one of eval, warning/span&gt;, echo/span&gt;, and include/span&gt; in the top of the code chunk, and for the fifth time include whatever combination of effect messages you would need to output this graph for a customer who was only interested in the outputs. ggplot(swfc_16,aes(Tot_Workforce_HC,Tot_Teachers_HC)) + geom_point() The final useful code chunk technique is ‘inline code’. Often we’ll want to calculate values from the data and report them in the text. Traditionally, if we were using Word and Excel, we’d calculate this in Excel, remember the number, and then type it up in Word - think of the things that could go wrong with that! We could get the number wrong when trying to remember it or we could type it wrong. R Markdown allows you to embed values in the text, so that it’s directly calculated from the data. To include an inline piece of code, write this: `r object_name` Activity: In your R Markdown file, write a code chunk that calculates the average total number of FTE Teaching Assistants (Tot_TAs_FTE) and call it ave_tot_tas_fte. Then write a sentence that states what the average total FTE of Teaching Assistants in each school is. Run the code and look at the output. 12.3 Multiple Reports Remember we wrote an lapply function to produce numerous graph for each different region? We can do the same for R Markdown reports to produce the same report for different entities, and whilst it’s got a few more steps than the lapply approach, the premise is the same. We’ll nned two file: The first is the actual R Markdown file, with a variable in it which will allow us to filter data to produce it for specific entities The second is an R script, which will iterate over the categories and produce a Markdown output for each of them. We’ll produce the R Markdown first. Activity: Open a new R Markdown and do the following: Remove the template in there currently Save the R Markdown file in the code file, and call it ‘region_factsheet’ Create a heading which has an inline code chunk with the variable region_name (this doesn’t currently exist - this is the object name that will be the iterand) Write a code chunk which loads in the tidyverse library and the School Workforce Census data - the code and outputs should be hidden (when you’re loading the data you’ll need data/swfc_2016_machine_readable.csv, because the R Markdown file is saved in the 2_code folder, so the says ‘go back up one step’) Write another code chunk that creates a numeric object (use as.numeric()) which is the number of schools in the region (you might have to trial this with an actual region before replacing it with region_name) Write a sentence which states the number of schools within the region, using region_name and your object from stage 5 in inline code within the sentence Write the code to plot the distribution of the school size within that region, using the code below ggplot(swfc_16 %&gt;% filter(Government_Office_Region_Name == region_name), aes(Tot_Workforce_HC)) + geom_histogram() + ggtitle(paste0(&#39;Distribution of school size in &#39;,region_name)) Next, we’ll produce the R script which will create each of the factsheets. Activity: Open a new R script and do the following: Load the tidyverse and rmarkdown libraries Load in the School Workforce Census Create an object which contains all the different levels of Government_Office_Region_Name called regions Create an lapply: The element which is going to have the function applied to each element of it is regions The object name in function() is region_name - this is the thing we want to change each time in the R Markdown file (look back at the R Markdown file you’ve just created if needs be) The function we’re going to apply is the render() function from the markdown package, it uses the code below render(&#39;2_code/region_factsheet.Rmd&#39;, #This is the name of the R Markdown file we want to produce an output from output_file = paste0(region_name,&quot;.html&quot;), #This is what the name of the output file will be - the region name and .html output_dir = &#39;outputs&#39;)) #They will be stored in the outputs directory RUN IT! And that’s it - hopefully by completing this course you’ve got a good introduction to the power of R! "]
]
